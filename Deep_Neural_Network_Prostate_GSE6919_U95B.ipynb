{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Information\n"
      ],
      "metadata": {
        "id": "G2mqUsvHbSx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TUGAS 1 - ADVANCE DEEP LEARNING\n",
        "\n",
        "NIM : 14230018\n",
        "\n",
        "NAMA : ILHAM MAULANA\n"
      ],
      "metadata": {
        "id": "j9xTIG0Xa-z-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link Collab : https://colab.research.google.com/drive/1K6xZbYdRAE7_QhEOlhq4zNqBAiZXI_XJ?usp=sharing"
      ],
      "metadata": {
        "id": "USVrCPkkbRPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laporan : https://docs.google.com/document/d/1xYNUiVXY-jPQIBeP3bgkzJPTSXdF_Kyns9kOgp88i4o/edit?usp=sharing"
      ],
      "metadata": {
        "id": "cV_M_Z75f5P0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpJSKkKKSNgF"
      },
      "source": [
        "## Dataset Cumida"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LdqVcZoXf7-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "22u3uugOo-Ee"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.activations import relu\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "import warnings;\n",
        "warnings.filterwarnings('ignore');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "wb-Ca7yLZwAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://sbcb.inf.ufrgs.br/cumida\n"
      ],
      "metadata": {
        "id": "l158_P_AZ2qx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://sbcb.inf.ufrgs.br/data/cumida/Genes/Prostate/GSE6919_U95B/Prostate_GSE6919_U95B.csv"
      ],
      "metadata": {
        "id": "ZAoO0MF0Z77u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7SU0gQvspNix"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load Data from CSV\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/k4ilham/dataset/main/Prostate_GSE6919_U95B.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Rr5NZS4IpdI8",
        "outputId": "8c6335c8-18e1-4570-ae19-6528dfbe01d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         samples                    type  41880_at  41881_at  41882_at  \\\n",
              "0  GSM152992.CEL  primary_prostate_tumor  2.414076  4.113824  2.035911   \n",
              "1  GSM152993.CEL  primary_prostate_tumor  2.385157  4.078664  2.123064   \n",
              "2  GSM152994.CEL  primary_prostate_tumor  2.295522  4.085505  2.144344   \n",
              "3  GSM152995.CEL  primary_prostate_tumor  2.260478  4.466391  2.206410   \n",
              "4  GSM152996.CEL  primary_prostate_tumor  2.229731  4.291435  2.506255   \n",
              "5  GSM152997.CEL  primary_prostate_tumor  2.323719  4.042794  2.219460   \n",
              "6  GSM152998.CEL  primary_prostate_tumor  2.557032  4.196903  2.122405   \n",
              "7  GSM152999.CEL  primary_prostate_tumor  2.441765  4.148545  1.968985   \n",
              "8  GSM153000.CEL  primary_prostate_tumor  2.604707  4.234341  2.167552   \n",
              "9  GSM153001.CEL  primary_prostate_tumor  2.364670  4.183144  1.866217   \n",
              "\n",
              "   41883_at  41884_at  41885_at  41886_r_at  41887_at  ...  AFFX-ThrX-3_at  \\\n",
              "0  3.102248  2.115578  1.775455    6.107839  2.160168  ...        2.955998   \n",
              "1  3.087631  2.254190  1.815183    5.708878  2.134447  ...        3.196521   \n",
              "2  3.071539  2.229422  1.985899    5.679248  2.100443  ...        2.929904   \n",
              "3  3.505265  2.605014  1.887307    5.935039  2.261295  ...        3.578538   \n",
              "4  3.220628  2.404673  1.886664    5.965917  2.274317  ...        3.558184   \n",
              "5  3.030761  2.539964  1.836586    5.970438  1.880250  ...        3.442099   \n",
              "6  3.495034  2.353686  2.100858    6.338756  2.019285  ...        3.542867   \n",
              "7  3.230116  2.240704  1.896051    6.166129  2.012576  ...        3.363998   \n",
              "8  3.394769  2.294088  2.089270    6.190621  2.030608  ...        3.703331   \n",
              "9  3.169024  2.371755  1.983816    5.748455  2.142535  ...        3.077640   \n",
              "\n",
              "   AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  AFFX-TrpnX-5_at  \\\n",
              "0        2.910953        2.095267         1.617076         2.060144   \n",
              "1        2.975412        2.249950         1.757867         2.352185   \n",
              "2        2.857025        2.047436         1.625339         2.065674   \n",
              "3        3.420946        2.736342         1.940826         2.713500   \n",
              "4        3.083316        2.562048         1.923414         2.775842   \n",
              "5        3.239850        2.373556         1.973410         2.563835   \n",
              "6        3.178389        2.413796         2.038962         2.723099   \n",
              "7        3.314865        2.345718         1.927122         2.600874   \n",
              "8        3.263648        2.769345         2.183191         2.621211   \n",
              "9        3.048728        2.230446         1.928804         2.466815   \n",
              "\n",
              "   AFFX-TrpnX-M_at  AFFX-YEL002c/WBP1_at  AFFX-YEL018w/_at  \\\n",
              "0         1.962483              1.919590          2.034229   \n",
              "1         2.054990              1.970140          1.768459   \n",
              "2         1.955286              1.768858          1.666836   \n",
              "3         2.363843              2.194837          1.981020   \n",
              "4         2.323899              2.288732          2.772796   \n",
              "5         2.172953              1.635655          1.885491   \n",
              "6         2.359402              2.495400          2.365220   \n",
              "7         2.354630              2.256550          2.220849   \n",
              "8         2.543716              2.483545          2.353530   \n",
              "9         2.228590              2.063278          2.016133   \n",
              "\n",
              "   AFFX-YEL021w/URA3_at  AFFX-YEL024w/RIP1_at  \n",
              "0              3.013061              2.208421  \n",
              "1              4.701207              2.513560  \n",
              "2              3.115166              2.136760  \n",
              "3              3.141350              2.550041  \n",
              "4              2.848256              2.803264  \n",
              "5              2.978715              2.603510  \n",
              "6              4.338475              3.266788  \n",
              "7              3.935853              2.800777  \n",
              "8              3.504419              2.823459  \n",
              "9              2.955133              2.590789  \n",
              "\n",
              "[10 rows x 12622 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7133f0c0-a41e-4af9-a3e7-28d89c3cf1c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>samples</th>\n",
              "      <th>type</th>\n",
              "      <th>41880_at</th>\n",
              "      <th>41881_at</th>\n",
              "      <th>41882_at</th>\n",
              "      <th>41883_at</th>\n",
              "      <th>41884_at</th>\n",
              "      <th>41885_at</th>\n",
              "      <th>41886_r_at</th>\n",
              "      <th>41887_at</th>\n",
              "      <th>...</th>\n",
              "      <th>AFFX-ThrX-3_at</th>\n",
              "      <th>AFFX-ThrX-5_at</th>\n",
              "      <th>AFFX-ThrX-M_at</th>\n",
              "      <th>AFFX-TrpnX-3_at</th>\n",
              "      <th>AFFX-TrpnX-5_at</th>\n",
              "      <th>AFFX-TrpnX-M_at</th>\n",
              "      <th>AFFX-YEL002c/WBP1_at</th>\n",
              "      <th>AFFX-YEL018w/_at</th>\n",
              "      <th>AFFX-YEL021w/URA3_at</th>\n",
              "      <th>AFFX-YEL024w/RIP1_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GSM152992.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.414076</td>\n",
              "      <td>4.113824</td>\n",
              "      <td>2.035911</td>\n",
              "      <td>3.102248</td>\n",
              "      <td>2.115578</td>\n",
              "      <td>1.775455</td>\n",
              "      <td>6.107839</td>\n",
              "      <td>2.160168</td>\n",
              "      <td>...</td>\n",
              "      <td>2.955998</td>\n",
              "      <td>2.910953</td>\n",
              "      <td>2.095267</td>\n",
              "      <td>1.617076</td>\n",
              "      <td>2.060144</td>\n",
              "      <td>1.962483</td>\n",
              "      <td>1.919590</td>\n",
              "      <td>2.034229</td>\n",
              "      <td>3.013061</td>\n",
              "      <td>2.208421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GSM152993.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.385157</td>\n",
              "      <td>4.078664</td>\n",
              "      <td>2.123064</td>\n",
              "      <td>3.087631</td>\n",
              "      <td>2.254190</td>\n",
              "      <td>1.815183</td>\n",
              "      <td>5.708878</td>\n",
              "      <td>2.134447</td>\n",
              "      <td>...</td>\n",
              "      <td>3.196521</td>\n",
              "      <td>2.975412</td>\n",
              "      <td>2.249950</td>\n",
              "      <td>1.757867</td>\n",
              "      <td>2.352185</td>\n",
              "      <td>2.054990</td>\n",
              "      <td>1.970140</td>\n",
              "      <td>1.768459</td>\n",
              "      <td>4.701207</td>\n",
              "      <td>2.513560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM152994.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.295522</td>\n",
              "      <td>4.085505</td>\n",
              "      <td>2.144344</td>\n",
              "      <td>3.071539</td>\n",
              "      <td>2.229422</td>\n",
              "      <td>1.985899</td>\n",
              "      <td>5.679248</td>\n",
              "      <td>2.100443</td>\n",
              "      <td>...</td>\n",
              "      <td>2.929904</td>\n",
              "      <td>2.857025</td>\n",
              "      <td>2.047436</td>\n",
              "      <td>1.625339</td>\n",
              "      <td>2.065674</td>\n",
              "      <td>1.955286</td>\n",
              "      <td>1.768858</td>\n",
              "      <td>1.666836</td>\n",
              "      <td>3.115166</td>\n",
              "      <td>2.136760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM152995.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.260478</td>\n",
              "      <td>4.466391</td>\n",
              "      <td>2.206410</td>\n",
              "      <td>3.505265</td>\n",
              "      <td>2.605014</td>\n",
              "      <td>1.887307</td>\n",
              "      <td>5.935039</td>\n",
              "      <td>2.261295</td>\n",
              "      <td>...</td>\n",
              "      <td>3.578538</td>\n",
              "      <td>3.420946</td>\n",
              "      <td>2.736342</td>\n",
              "      <td>1.940826</td>\n",
              "      <td>2.713500</td>\n",
              "      <td>2.363843</td>\n",
              "      <td>2.194837</td>\n",
              "      <td>1.981020</td>\n",
              "      <td>3.141350</td>\n",
              "      <td>2.550041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GSM152996.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.229731</td>\n",
              "      <td>4.291435</td>\n",
              "      <td>2.506255</td>\n",
              "      <td>3.220628</td>\n",
              "      <td>2.404673</td>\n",
              "      <td>1.886664</td>\n",
              "      <td>5.965917</td>\n",
              "      <td>2.274317</td>\n",
              "      <td>...</td>\n",
              "      <td>3.558184</td>\n",
              "      <td>3.083316</td>\n",
              "      <td>2.562048</td>\n",
              "      <td>1.923414</td>\n",
              "      <td>2.775842</td>\n",
              "      <td>2.323899</td>\n",
              "      <td>2.288732</td>\n",
              "      <td>2.772796</td>\n",
              "      <td>2.848256</td>\n",
              "      <td>2.803264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GSM152997.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.323719</td>\n",
              "      <td>4.042794</td>\n",
              "      <td>2.219460</td>\n",
              "      <td>3.030761</td>\n",
              "      <td>2.539964</td>\n",
              "      <td>1.836586</td>\n",
              "      <td>5.970438</td>\n",
              "      <td>1.880250</td>\n",
              "      <td>...</td>\n",
              "      <td>3.442099</td>\n",
              "      <td>3.239850</td>\n",
              "      <td>2.373556</td>\n",
              "      <td>1.973410</td>\n",
              "      <td>2.563835</td>\n",
              "      <td>2.172953</td>\n",
              "      <td>1.635655</td>\n",
              "      <td>1.885491</td>\n",
              "      <td>2.978715</td>\n",
              "      <td>2.603510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GSM152998.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.557032</td>\n",
              "      <td>4.196903</td>\n",
              "      <td>2.122405</td>\n",
              "      <td>3.495034</td>\n",
              "      <td>2.353686</td>\n",
              "      <td>2.100858</td>\n",
              "      <td>6.338756</td>\n",
              "      <td>2.019285</td>\n",
              "      <td>...</td>\n",
              "      <td>3.542867</td>\n",
              "      <td>3.178389</td>\n",
              "      <td>2.413796</td>\n",
              "      <td>2.038962</td>\n",
              "      <td>2.723099</td>\n",
              "      <td>2.359402</td>\n",
              "      <td>2.495400</td>\n",
              "      <td>2.365220</td>\n",
              "      <td>4.338475</td>\n",
              "      <td>3.266788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GSM152999.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.441765</td>\n",
              "      <td>4.148545</td>\n",
              "      <td>1.968985</td>\n",
              "      <td>3.230116</td>\n",
              "      <td>2.240704</td>\n",
              "      <td>1.896051</td>\n",
              "      <td>6.166129</td>\n",
              "      <td>2.012576</td>\n",
              "      <td>...</td>\n",
              "      <td>3.363998</td>\n",
              "      <td>3.314865</td>\n",
              "      <td>2.345718</td>\n",
              "      <td>1.927122</td>\n",
              "      <td>2.600874</td>\n",
              "      <td>2.354630</td>\n",
              "      <td>2.256550</td>\n",
              "      <td>2.220849</td>\n",
              "      <td>3.935853</td>\n",
              "      <td>2.800777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GSM153000.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.604707</td>\n",
              "      <td>4.234341</td>\n",
              "      <td>2.167552</td>\n",
              "      <td>3.394769</td>\n",
              "      <td>2.294088</td>\n",
              "      <td>2.089270</td>\n",
              "      <td>6.190621</td>\n",
              "      <td>2.030608</td>\n",
              "      <td>...</td>\n",
              "      <td>3.703331</td>\n",
              "      <td>3.263648</td>\n",
              "      <td>2.769345</td>\n",
              "      <td>2.183191</td>\n",
              "      <td>2.621211</td>\n",
              "      <td>2.543716</td>\n",
              "      <td>2.483545</td>\n",
              "      <td>2.353530</td>\n",
              "      <td>3.504419</td>\n",
              "      <td>2.823459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GSM153001.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.364670</td>\n",
              "      <td>4.183144</td>\n",
              "      <td>1.866217</td>\n",
              "      <td>3.169024</td>\n",
              "      <td>2.371755</td>\n",
              "      <td>1.983816</td>\n",
              "      <td>5.748455</td>\n",
              "      <td>2.142535</td>\n",
              "      <td>...</td>\n",
              "      <td>3.077640</td>\n",
              "      <td>3.048728</td>\n",
              "      <td>2.230446</td>\n",
              "      <td>1.928804</td>\n",
              "      <td>2.466815</td>\n",
              "      <td>2.228590</td>\n",
              "      <td>2.063278</td>\n",
              "      <td>2.016133</td>\n",
              "      <td>2.955133</td>\n",
              "      <td>2.590789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 12622 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7133f0c0-a41e-4af9-a3e7-28d89c3cf1c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7133f0c0-a41e-4af9-a3e7-28d89c3cf1c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7133f0c0-a41e-4af9-a3e7-28d89c3cf1c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23c63ec8-81fa-4f6b-9622-ca99142e8d8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23c63ec8-81fa-4f6b-9622-ca99142e8d8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23c63ec8-81fa-4f6b-9622-ca99142e8d8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aQCODWGvpjRH"
      },
      "outputs": [],
      "source": [
        "X = df.drop(df.columns[[0, 1]], axis=1)\n",
        "y = df['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvTu93QYplse",
        "outputId": "fb3f625b-e3ab-4820-c930-dff9bc268408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n8blSMxGpo8D"
      },
      "outputs": [],
      "source": [
        "# Encoding label menjadi angka menggunakan LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVsIkRwfp1mz",
        "outputId": "98d825e1-510d-4142-8952-3aff2428544c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(79, 12620)\n"
          ]
        }
      ],
      "source": [
        "# Bagi data menjadi data pelatihan, validasi, dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GBGA47G6p7Lo"
      },
      "outputs": [],
      "source": [
        "# Normalisasi data\n",
        "#scaler = StandardScaler()\n",
        "#X_train_scaled = scaler.fit_transform(X_train)\n",
        "#X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CZHGWpsvmA6A"
      },
      "outputs": [],
      "source": [
        "# Membuat DataFrame kosong untuk menyimpan hasil evaluasi\n",
        "results_df = pd.DataFrame(columns=['Optimizer', 'Hidden Layers', 'Validation Accuracy', 'Test Accuracy'])\n",
        "\n",
        "# Fungsi untuk menambahkan atau memperbarui nilai dalam DataFrame\n",
        "def update_results(optimizer, hidden_layers, val_acc, test_acc):\n",
        "    global results_df\n",
        "    # Mencari baris yang sesuai dengan kombinasi optimizer dan hidden layers\n",
        "    mask = (results_df['Optimizer'] == optimizer) & (results_df['Hidden Layers'] == hidden_layers)\n",
        "    # Jika kombinasi sudah ada, update nilai\n",
        "    if mask.any():\n",
        "        results_df.loc[mask, ['Validation Accuracy', 'Test Accuracy']] = val_acc, test_acc\n",
        "    # Jika kombinasi belum ada, tambahkan baris baru\n",
        "    else:\n",
        "        results_df = pd.concat([results_df, pd.DataFrame({'Optimizer': [optimizer],\n",
        "                                                          'Hidden Layers': [hidden_layers],\n",
        "                                                          'Validation Accuracy': [val_acc],\n",
        "                                                          'Test Accuracy': [test_acc]})],\n",
        "                                ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Membangun 4 DNN"
      ],
      "metadata": {
        "id": "8wDjsvqYaKqp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4647rE3qA2y"
      },
      "source": [
        "### 1.A. Hidden layer 1: 1000 neurons, ReLU activation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "avAmoFJUbkcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wCssAxasqCDJ"
      },
      "outputs": [],
      "source": [
        "# Function to build the DNN model with one hidden layer\n",
        "def build_model_one_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(1000, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer with 1000 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')          # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAP0arySqv_S"
      },
      "source": [
        "### 1.B. Hidden layer 2: 500 neurons, ReLU activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8oUl8cFnqyI1"
      },
      "outputs": [],
      "source": [
        "# Function to build the DNN model with two hidden layer\n",
        "def build_model_two_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(500, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # 1st hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(500, activation='relu'),                                   # 2nd hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t58L64LfqJ_p"
      },
      "source": [
        "### 1.C. Hidden layer 3: 250 neurons, ReLU activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QZ9bviDJqKtE"
      },
      "outputs": [],
      "source": [
        "# Function to build the DNN model with three hidden layer\n",
        "def build_model_three_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(250, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Second hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Third hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tiad0rJSqUSX"
      },
      "source": [
        "### 1.D. Hidden layer 4: 100 neurons, ReLU activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JvCg7eIdqU0T"
      },
      "outputs": [],
      "source": [
        "# Function to build the DNN model with four hidden layer\n",
        "def build_model_four_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Second hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Third hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Fourth hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZoLHmPLgqdl2"
      },
      "outputs": [],
      "source": [
        "# Build the DNN model\n",
        "model_one_hidden_layer = build_model_one_hidden()\n",
        "model_two_hidden_layer = build_model_two_hidden()\n",
        "model_three_hidden_layer = build_model_three_hidden()\n",
        "model_four_hidden_layer = build_model_four_hidden()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtWZHqXpq8Qv"
      },
      "source": [
        "### 1.E. Optimizer: SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3LHpZyoq-hK"
      },
      "source": [
        "#### Train and evaluate the model with 1 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvXQ6gdTrAha",
        "outputId": "ce793700-b314-4b60-c924-02bc87cf16d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 3s 254ms/step - loss: 2.1317 - accuracy: 0.4937 - val_loss: 0.8953 - val_accuracy: 0.8000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 0.2631 - accuracy: 0.8987 - val_loss: 1.3083 - val_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0883 - accuracy: 0.9747 - val_loss: 1.0391 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0354 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 235ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0342 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 160ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0333 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 9.7298e-04 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 9.0486e-04 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 172ms/step - loss: 8.4411e-04 - accuracy: 1.0000 - val_loss: 1.0334 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 7.9010e-04 - accuracy: 1.0000 - val_loss: 1.0336 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 7.4799e-04 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 7.0965e-04 - accuracy: 1.0000 - val_loss: 1.0345 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 6.7605e-04 - accuracy: 1.0000 - val_loss: 1.0349 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 6.4595e-04 - accuracy: 1.0000 - val_loss: 1.0354 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 6.1884e-04 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 5.9399e-04 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 5.7273e-04 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 5.5109e-04 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 5.3201e-04 - accuracy: 1.0000 - val_loss: 1.0377 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 5.1507e-04 - accuracy: 1.0000 - val_loss: 1.0383 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 4.9957e-04 - accuracy: 1.0000 - val_loss: 1.0388 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 4.8454e-04 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 4.7047e-04 - accuracy: 1.0000 - val_loss: 1.0396 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 4.5765e-04 - accuracy: 1.0000 - val_loss: 1.0402 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 4.4549e-04 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 4.3372e-04 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 4.2243e-04 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 4.1296e-04 - accuracy: 1.0000 - val_loss: 1.0424 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 4.0294e-04 - accuracy: 1.0000 - val_loss: 1.0430 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 3.9396e-04 - accuracy: 1.0000 - val_loss: 1.0436 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 3.8502e-04 - accuracy: 1.0000 - val_loss: 1.0440 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 3.7677e-04 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 3.6900e-04 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 3.6166e-04 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 3.5420e-04 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 3.4726e-04 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 3.4066e-04 - accuracy: 1.0000 - val_loss: 1.0472 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 3.3452e-04 - accuracy: 1.0000 - val_loss: 1.0477 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 3.2849e-04 - accuracy: 1.0000 - val_loss: 1.0483 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 3.2277e-04 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 3.1710e-04 - accuracy: 1.0000 - val_loss: 1.0493 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 3.1164e-04 - accuracy: 1.0000 - val_loss: 1.0498 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 3.0685e-04 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 3.0159e-04 - accuracy: 1.0000 - val_loss: 1.0508 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 2.9673e-04 - accuracy: 1.0000 - val_loss: 1.0512 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.9215e-04 - accuracy: 1.0000 - val_loss: 1.0518 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 2.8754e-04 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.8328e-04 - accuracy: 1.0000 - val_loss: 1.0527 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 2.7909e-04 - accuracy: 1.0000 - val_loss: 1.0531 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 2.7495e-04 - accuracy: 1.0000 - val_loss: 1.0535 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 2.7119e-04 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 2.6741e-04 - accuracy: 1.0000 - val_loss: 1.0545 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 2.6361e-04 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 2.6008e-04 - accuracy: 1.0000 - val_loss: 1.0554 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.5667e-04 - accuracy: 1.0000 - val_loss: 1.0559 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 2.5314e-04 - accuracy: 1.0000 - val_loss: 1.0563 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 2.5000e-04 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 2.4681e-04 - accuracy: 1.0000 - val_loss: 1.0572 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 2.4368e-04 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 2.4082e-04 - accuracy: 1.0000 - val_loss: 1.0581 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 2.3783e-04 - accuracy: 1.0000 - val_loss: 1.0586 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 2.3506e-04 - accuracy: 1.0000 - val_loss: 1.0590 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 2.3229e-04 - accuracy: 1.0000 - val_loss: 1.0594 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.2961e-04 - accuracy: 1.0000 - val_loss: 1.0598 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.2704e-04 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 2.2447e-04 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 2.2197e-04 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 2.1952e-04 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 2.1712e-04 - accuracy: 1.0000 - val_loss: 1.0618 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 2.1477e-04 - accuracy: 1.0000 - val_loss: 1.0622 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 2.1258e-04 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 2.1039e-04 - accuracy: 1.0000 - val_loss: 1.0629 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 132ms/step - loss: 2.0816e-04 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 2.0608e-04 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 2.0409e-04 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 2.0199e-04 - accuracy: 1.0000 - val_loss: 1.0644 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 2.0005e-04 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.9822e-04 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.9623e-04 - accuracy: 1.0000 - val_loss: 1.0656 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.9440e-04 - accuracy: 1.0000 - val_loss: 1.0659 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.9257e-04 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.9071e-04 - accuracy: 1.0000 - val_loss: 1.0667 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.8904e-04 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.8735e-04 - accuracy: 1.0000 - val_loss: 1.0674 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.8574e-04 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.8411e-04 - accuracy: 1.0000 - val_loss: 1.0682 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.8241e-04 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.8088e-04 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.7934e-04 - accuracy: 1.0000 - val_loss: 1.0692 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.7781e-04 - accuracy: 1.0000 - val_loss: 1.0695 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.7639e-04 - accuracy: 1.0000 - val_loss: 1.0699 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: 1.7486e-04 - accuracy: 1.0000 - val_loss: 1.0702 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.7349e-04 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.7207e-04 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7063e-04 - accuracy: 1.0000 - val_loss: 1.0712 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 1.6931e-04 - accuracy: 1.0000 - val_loss: 1.0715 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6796e-04 - accuracy: 1.0000 - val_loss: 1.0718 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 1.6666e-04 - accuracy: 1.0000 - val_loss: 1.0721 - val_accuracy: 0.7500\n",
            "CPU times: user 1min 9s, sys: 32.1 s, total: 1min 41s\n",
            "Wall time: 1min 17s\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "# optimizer_sgd = tf.keras.optimizers.SGD(learning_rate=0.01)  # Define the optimizer with learning rate\n",
        "%%time\n",
        "model_one_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "RK8Yv1C0BcBc",
        "outputId": "2147dc60-df2d-4930-e8f7-355fcb9628c7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training', 'validation'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IAeB-djPsS_1"
      },
      "outputs": [],
      "source": [
        "# Ambil loss dari history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "BedSLfcTUkme",
        "outputId": "2d04ad7c-28bb-4c42-9732-ef2074f29d20"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot kurva loss\n",
        "plt.plot(epochs, train_loss, 'g', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAlFG684Vg7Q",
        "outputId": "6ded5793-633a-4e22-a5e5-f889ad72d31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 155ms/step - loss: 1.0721 - accuracy: 0.7500\n",
            "Model Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.6707 - accuracy: 0.6400\n",
            "Best Model Test Accuracy: 0.6399999856948853\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6325bl5F-QsO",
        "outputId": "d120c47a-a157-4676-fa34-8c7f7d908bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step - loss: 1.6707 - accuracy: 0.6400\n"
          ]
        }
      ],
      "source": [
        "results = model_one_hidden_layer.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gAunOFmPCS",
        "outputId": "4f2af489-93cd-43f6-d5af-0ab9aaacdd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCPOe4QYtr0L"
      },
      "source": [
        "#### Train and evaluate the model with 2 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhJ6YMkTtsYE",
        "outputId": "1f2584b1-6f46-4078-e52f-521c9a08654a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.9201 - accuracy: 0.5823 - val_loss: 0.7521 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0694 - accuracy: 0.9873 - val_loss: 0.7501 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7859 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8223 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8276 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8295 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8312 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8328 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8374 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8390 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8403 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8419 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8432 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8445 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8474 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8486 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8500 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8513 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8559 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8571 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8582 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8594 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8626 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8669 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8680 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8690 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8700 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8710 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 9.9185e-04 - accuracy: 1.0000 - val_loss: 0.8740 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 9.7658e-04 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 9.6206e-04 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 9.4784e-04 - accuracy: 1.0000 - val_loss: 0.8767 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 9.3396e-04 - accuracy: 1.0000 - val_loss: 0.8778 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 9.2057e-04 - accuracy: 1.0000 - val_loss: 0.8787 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 9.0735e-04 - accuracy: 1.0000 - val_loss: 0.8796 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 8.9508e-04 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 8.8268e-04 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 8.7055e-04 - accuracy: 1.0000 - val_loss: 0.8823 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 8.5917e-04 - accuracy: 1.0000 - val_loss: 0.8832 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 8.4737e-04 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 8.3655e-04 - accuracy: 1.0000 - val_loss: 0.8850 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 8.2549e-04 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 8.1503e-04 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 8.0493e-04 - accuracy: 1.0000 - val_loss: 0.8875 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 7.9500e-04 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 7.8523e-04 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 7.7525e-04 - accuracy: 1.0000 - val_loss: 0.8899 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 7.6604e-04 - accuracy: 1.0000 - val_loss: 0.8907 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 7.5700e-04 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 7.4797e-04 - accuracy: 1.0000 - val_loss: 0.8923 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 7.3928e-04 - accuracy: 1.0000 - val_loss: 0.8931 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 7.3083e-04 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 7.2243e-04 - accuracy: 1.0000 - val_loss: 0.8947 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 7.1416e-04 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 7.0606e-04 - accuracy: 1.0000 - val_loss: 0.8961 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.9807e-04 - accuracy: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 6.9046e-04 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 6.8313e-04 - accuracy: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 6.7569e-04 - accuracy: 1.0000 - val_loss: 0.8990 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 6.6830e-04 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.6115e-04 - accuracy: 1.0000 - val_loss: 0.9006 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 6.5425e-04 - accuracy: 1.0000 - val_loss: 0.9012 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 6.4751e-04 - accuracy: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 6.4077e-04 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_two_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "U9mz3XslyAlU"
      },
      "outputs": [],
      "source": [
        "# Ambil loss dari history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_loss) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SA4RYiRkyD-E",
        "outputId": "75aff01d-7a63-4e74-f418-b262e7f5d761"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot kurva loss\n",
        "plt.plot(epochs, train_loss, 'g', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4YlOKSMyJ3_",
        "outputId": "9a27a132-3730-4bbd-8ae4-ab8c26d30672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 142ms/step - loss: 0.9026 - accuracy: 0.7500\n",
            "Model 2 Hidden Layer SGD Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6905 - accuracy: 0.6400\n",
            "Best Model Test Accuracy: 0.6399999856948853\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# 5. Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# 6. Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xadhxzGpmcjO",
        "outputId": "a795cf16-5898-46a5-8331-2be5e45e2f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIVSqdm9yWdF"
      },
      "source": [
        "#### Train and evaluate the model with 3 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJCNzfvLyY28",
        "outputId": "4f51e405-34aa-45d3-e6ac-1a06792a97b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.6881 - accuracy: 0.5316 - val_loss: 0.6089 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.1825 - accuracy: 0.9747 - val_loss: 0.5700 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.5800 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.5942 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.6086 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6307 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7415 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7593 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7679 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7703 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9.9855e-04 - accuracy: 1.0000 - val_loss: 0.7748 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.8534e-04 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.7267e-04 - accuracy: 1.0000 - val_loss: 0.7769 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.6005e-04 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.4755e-04 - accuracy: 1.0000 - val_loss: 0.7791 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 9.3555e-04 - accuracy: 1.0000 - val_loss: 0.7800 - val_accuracy: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_three_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGxkomxAyrgV",
        "outputId": "ef2f6410-0fbd-4aeb-81c4-152ba665c3aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 170ms/step - loss: 0.7800 - accuracy: 0.7000\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7084 - accuracy: 0.6800\n",
            "Best Model Test Accuracy: 0.6800000071525574\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AUn7KhOmk06",
        "outputId": "8045e38c-23f2-4001-c78b-a6361bf2d3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB6c--fUy36r"
      },
      "source": [
        "#### Train and evaluate the model with 4 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQOI7pOty61V",
        "outputId": "8a1c7672-68f0-4406-839e-dc50a1c3b4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 0.6447 - accuracy: 0.6076 - val_loss: 0.6271 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2996 - accuracy: 0.9241 - val_loss: 0.6289 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1756 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1091 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.8248 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.8559 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.8670 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8796 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9451 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9528 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9864 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9931 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9980 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0045 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0101 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0259 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0305 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0347 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0397 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0492 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0531 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0576 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0654 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0699 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0770 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0952 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1172 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1233 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1264 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1291 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1316 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1343 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1396 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1422 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1448 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1478 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1498 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1526 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1574 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1600 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1624 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1645 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.8532e-04 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.6834e-04 - accuracy: 1.0000 - val_loss: 1.1717 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.5154e-04 - accuracy: 1.0000 - val_loss: 1.1737 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.3554e-04 - accuracy: 1.0000 - val_loss: 1.1760 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.1957e-04 - accuracy: 1.0000 - val_loss: 1.1783 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.0420e-04 - accuracy: 1.0000 - val_loss: 1.1804 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.8982e-04 - accuracy: 1.0000 - val_loss: 1.1825 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.7556e-04 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 8.6183e-04 - accuracy: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.4806e-04 - accuracy: 1.0000 - val_loss: 1.1888 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.3518e-04 - accuracy: 1.0000 - val_loss: 1.1907 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8.2222e-04 - accuracy: 1.0000 - val_loss: 1.1929 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.0997e-04 - accuracy: 1.0000 - val_loss: 1.1949 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.9800e-04 - accuracy: 1.0000 - val_loss: 1.1969 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.8619e-04 - accuracy: 1.0000 - val_loss: 1.1986 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.7479e-04 - accuracy: 1.0000 - val_loss: 1.2005 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 7.6337e-04 - accuracy: 1.0000 - val_loss: 1.2025 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.5243e-04 - accuracy: 1.0000 - val_loss: 1.2045 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 7.4200e-04 - accuracy: 1.0000 - val_loss: 1.2063 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.3169e-04 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.2161e-04 - accuracy: 1.0000 - val_loss: 1.2100 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 7.1172e-04 - accuracy: 1.0000 - val_loss: 1.2117 - val_accuracy: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_four_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36rrp5yhzEcA",
        "outputId": "a873ce84-cd0e-4886-e04b-539c1bb9c5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 150ms/step - loss: 1.2117 - accuracy: 0.7000\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1738 - accuracy: 0.6400\n",
            "Best Model Test Accuracy: 0.6399999856948853\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRzFcqnXmshC",
        "outputId": "e0de33e3-3945-4cc6-8a67-4e6a364df1bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n",
            "3       SGD             4                 0.70           0.64\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtsGTG8N2opl"
      },
      "source": [
        "## 2. Mengganti Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.A Adam"
      ],
      "metadata": {
        "id": "rwWPwPzkcdMX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcdu_-RB2q4I"
      },
      "source": [
        "#### Train and evaluate the model with 1 hidden Layer with Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sivm9xLk2tlF",
        "outputId": "d2601ff5-382a-445a-f9d7-09d884770a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 4.7212 - accuracy: 0.7342 - val_loss: 11.3002 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 7.4855 - accuracy: 0.7848 - val_loss: 11.7077 - val_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 1.7129 - accuracy: 0.9241 - val_loss: 13.4312 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 3s 319ms/step - loss: 2.4939e-04 - accuracy: 1.0000 - val_loss: 18.8343 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 0.1196 - accuracy: 0.9873 - val_loss: 19.9833 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 3.8927e-04 - accuracy: 1.0000 - val_loss: 19.6862 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 2.1414e-04 - accuracy: 1.0000 - val_loss: 19.6455 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 2s 218ms/step - loss: 9.0385e-07 - accuracy: 1.0000 - val_loss: 19.6473 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 5.3115e-07 - accuracy: 1.0000 - val_loss: 19.6480 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 2.3540e-07 - accuracy: 1.0000 - val_loss: 19.6485 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 1.6599e-07 - accuracy: 1.0000 - val_loss: 19.6487 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 1.3581e-07 - accuracy: 1.0000 - val_loss: 19.6488 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 1.3128e-07 - accuracy: 1.0000 - val_loss: 19.6487 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.2977e-07 - accuracy: 1.0000 - val_loss: 19.6487 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 1.2826e-07 - accuracy: 1.0000 - val_loss: 19.6486 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 1.2675e-07 - accuracy: 1.0000 - val_loss: 19.6485 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 2s 301ms/step - loss: 1.2524e-07 - accuracy: 1.0000 - val_loss: 19.6484 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 2s 247ms/step - loss: 1.2524e-07 - accuracy: 1.0000 - val_loss: 19.6483 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 2s 314ms/step - loss: 1.2374e-07 - accuracy: 1.0000 - val_loss: 19.6482 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 2s 242ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 19.6481 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 19.6480 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 19.6479 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 19.6478 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 19.6476 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.2072e-07 - accuracy: 1.0000 - val_loss: 19.6475 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 1.2072e-07 - accuracy: 1.0000 - val_loss: 19.6474 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 1.2072e-07 - accuracy: 1.0000 - val_loss: 19.6473 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 19.6471 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 2s 218ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 19.6470 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 2s 296ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 19.6469 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 19.6468 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 1.1770e-07 - accuracy: 1.0000 - val_loss: 19.6467 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 1.1770e-07 - accuracy: 1.0000 - val_loss: 19.6466 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 1.1770e-07 - accuracy: 1.0000 - val_loss: 19.6464 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 1.1619e-07 - accuracy: 1.0000 - val_loss: 19.6463 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 1.1619e-07 - accuracy: 1.0000 - val_loss: 19.6461 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 3s 335ms/step - loss: 1.1619e-07 - accuracy: 1.0000 - val_loss: 19.6460 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 1.1468e-07 - accuracy: 1.0000 - val_loss: 19.6458 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 2s 214ms/step - loss: 1.1468e-07 - accuracy: 1.0000 - val_loss: 19.6457 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.1468e-07 - accuracy: 1.0000 - val_loss: 19.6456 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 1.1468e-07 - accuracy: 1.0000 - val_loss: 19.6454 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.1317e-07 - accuracy: 1.0000 - val_loss: 19.6452 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 2s 223ms/step - loss: 1.1317e-07 - accuracy: 1.0000 - val_loss: 19.6451 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 1.1317e-07 - accuracy: 1.0000 - val_loss: 19.6450 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 1.1166e-07 - accuracy: 1.0000 - val_loss: 19.6448 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 1.1166e-07 - accuracy: 1.0000 - val_loss: 19.6446 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.1166e-07 - accuracy: 1.0000 - val_loss: 19.6445 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.1016e-07 - accuracy: 1.0000 - val_loss: 19.6443 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 1.1016e-07 - accuracy: 1.0000 - val_loss: 19.6442 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 1.1016e-07 - accuracy: 1.0000 - val_loss: 19.6440 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 3s 319ms/step - loss: 1.0865e-07 - accuracy: 1.0000 - val_loss: 19.6439 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 2s 211ms/step - loss: 1.0714e-07 - accuracy: 1.0000 - val_loss: 19.6437 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 1.0714e-07 - accuracy: 1.0000 - val_loss: 19.6436 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 1.0714e-07 - accuracy: 1.0000 - val_loss: 19.6434 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 1.0563e-07 - accuracy: 1.0000 - val_loss: 19.6432 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 1.0563e-07 - accuracy: 1.0000 - val_loss: 19.6431 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 1.0563e-07 - accuracy: 1.0000 - val_loss: 19.6429 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 2s 302ms/step - loss: 1.0412e-07 - accuracy: 1.0000 - val_loss: 19.6428 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 1.0412e-07 - accuracy: 1.0000 - val_loss: 19.6426 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 2s 211ms/step - loss: 1.0412e-07 - accuracy: 1.0000 - val_loss: 19.6424 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 2s 220ms/step - loss: 1.0261e-07 - accuracy: 1.0000 - val_loss: 19.6423 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 2s 218ms/step - loss: 1.0261e-07 - accuracy: 1.0000 - val_loss: 19.6421 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 1.0261e-07 - accuracy: 1.0000 - val_loss: 19.6419 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 1.0261e-07 - accuracy: 1.0000 - val_loss: 19.6417 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 1.0110e-07 - accuracy: 1.0000 - val_loss: 19.6416 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 1.0110e-07 - accuracy: 1.0000 - val_loss: 19.6414 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 2s 304ms/step - loss: 1.0110e-07 - accuracy: 1.0000 - val_loss: 19.6413 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 1.0110e-07 - accuracy: 1.0000 - val_loss: 19.6410 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 2s 214ms/step - loss: 9.9592e-08 - accuracy: 1.0000 - val_loss: 19.6408 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 9.9592e-08 - accuracy: 1.0000 - val_loss: 19.6407 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 2s 303ms/step - loss: 9.9592e-08 - accuracy: 1.0000 - val_loss: 19.6405 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 9.8083e-08 - accuracy: 1.0000 - val_loss: 19.6403 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 9.8083e-08 - accuracy: 1.0000 - val_loss: 19.6401 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 9.6574e-08 - accuracy: 1.0000 - val_loss: 19.6400 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 2s 221ms/step - loss: 9.5065e-08 - accuracy: 1.0000 - val_loss: 19.6399 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 2s 218ms/step - loss: 9.5065e-08 - accuracy: 1.0000 - val_loss: 19.6397 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 9.5065e-08 - accuracy: 1.0000 - val_loss: 19.6395 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 9.3556e-08 - accuracy: 1.0000 - val_loss: 19.6393 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 9.3556e-08 - accuracy: 1.0000 - val_loss: 19.6392 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 9.3556e-08 - accuracy: 1.0000 - val_loss: 19.6390 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 2s 220ms/step - loss: 9.3556e-08 - accuracy: 1.0000 - val_loss: 19.6388 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 9.2047e-08 - accuracy: 1.0000 - val_loss: 19.6386 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 2s 220ms/step - loss: 9.2047e-08 - accuracy: 1.0000 - val_loss: 19.6384 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 9.2047e-08 - accuracy: 1.0000 - val_loss: 19.6383 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 2s 223ms/step - loss: 9.0539e-08 - accuracy: 1.0000 - val_loss: 19.6380 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 2s 222ms/step - loss: 9.0539e-08 - accuracy: 1.0000 - val_loss: 19.6379 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 9.0539e-08 - accuracy: 1.0000 - val_loss: 19.6377 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 2s 214ms/step - loss: 8.9030e-08 - accuracy: 1.0000 - val_loss: 19.6375 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 2s 218ms/step - loss: 8.9030e-08 - accuracy: 1.0000 - val_loss: 19.6373 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 2s 223ms/step - loss: 8.9030e-08 - accuracy: 1.0000 - val_loss: 19.6372 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 3s 331ms/step - loss: 8.9030e-08 - accuracy: 1.0000 - val_loss: 19.6369 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 8.7521e-08 - accuracy: 1.0000 - val_loss: 19.6367 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 2s 218ms/step - loss: 8.7521e-08 - accuracy: 1.0000 - val_loss: 19.6366 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 8.7521e-08 - accuracy: 1.0000 - val_loss: 19.6364 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 8.6012e-08 - accuracy: 1.0000 - val_loss: 19.6362 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 2s 214ms/step - loss: 8.6012e-08 - accuracy: 1.0000 - val_loss: 19.6360 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 2s 245ms/step - loss: 8.4503e-08 - accuracy: 1.0000 - val_loss: 19.6358 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 3s 309ms/step - loss: 8.4503e-08 - accuracy: 1.0000 - val_loss: 19.6356 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 2s 220ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6354 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6353 - val_accuracy: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "# optimizer_adam = tf.keras.optimizers.Adam(learning_rate=0.001)  # Define the optimizer with learning rate\n",
        "model_one_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw5LBLti4iqd",
        "outputId": "f1b1cbad-bb5c-40cc-8a21-26959d05cc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 144ms/step - loss: 19.6353 - accuracy: 0.7000\n",
            "Model 1 Hidden Layer Adam Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 19.2272 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 1 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_VrN6DSmzjn",
        "outputId": "ff8ddc94-dec1-4275-809e-904a91ed69ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n",
            "3       SGD             4                 0.70           0.64\n",
            "4      ADAM             1                 0.70           0.60\n"
          ]
        }
      ],
      "source": [
        "update_results('ADAM', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr-KfD3n4sI2"
      },
      "source": [
        "#### Train and evaluate the model with 2 hidden Layer with Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHML5eST4uf8",
        "outputId": "c4d6ad1c-55ad-4c8b-f170-3a81fa792f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 2.4223 - accuracy: 0.7468 - val_loss: 2.6559 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.1013 - accuracy: 0.8608 - val_loss: 3.3123 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 0.7273 - accuracy: 0.9494 - val_loss: 4.5205 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.1750 - accuracy: 0.8987 - val_loss: 12.7009 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.5707 - accuracy: 0.9620 - val_loss: 9.7664 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.5264 - accuracy: 0.9747 - val_loss: 11.9333 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 0.5949 - accuracy: 0.9620 - val_loss: 16.2812 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 0.7288 - accuracy: 0.9367 - val_loss: 14.4055 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 5.6247e-04 - accuracy: 1.0000 - val_loss: 12.3051 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 11.7545 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.9315e-07 - accuracy: 1.0000 - val_loss: 11.5593 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 6.6395e-08 - accuracy: 1.0000 - val_loss: 11.4648 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 2.2635e-08 - accuracy: 1.0000 - val_loss: 11.4234 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 11.4050 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 11.3968 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3931 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3914 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 138ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3901 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 110ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3902 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 131ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_two_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrS0LpCf578Z",
        "outputId": "48e50512-61b2-4878-8655-a65a7a298a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 145ms/step - loss: 11.3903 - accuracy: 0.7500\n",
            "Model 2 Hidden Layer Adam Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.7588 - accuracy: 0.6400\n",
            "Best Model Test Accuracy: 0.6399999856948853\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prVeza55nC9K",
        "outputId": "eeb1be61-3ff1-4341-c85e-ab7f715e59c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n",
            "3       SGD             4                 0.70           0.64\n",
            "4      ADAM             1                 0.70           0.60\n",
            "5      ADAM             2                 0.75           0.64\n"
          ]
        }
      ],
      "source": [
        "update_results('ADAM', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBco_lbK8_ON"
      },
      "source": [
        "#### Train and evaluate the model with 3 hidden Layer with Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIMeNscg9BlI",
        "outputId": "f899a682-d383-48a0-c414-d30f52afd0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.1586 - accuracy: 0.7595 - val_loss: 3.5777 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.7097 - accuracy: 0.7595 - val_loss: 2.3722 - val_accuracy: 0.5500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.5117 - accuracy: 0.7848 - val_loss: 3.6433 - val_accuracy: 0.8000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.4288 - accuracy: 0.9241 - val_loss: 4.8672 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1004 - accuracy: 0.9620 - val_loss: 4.2492 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0135 - accuracy: 0.9873 - val_loss: 4.5121 - val_accuracy: 0.5500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4247e-04 - accuracy: 1.0000 - val_loss: 4.8083 - val_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 7.5359e-05 - accuracy: 1.0000 - val_loss: 4.9603 - val_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 8.4638e-05 - accuracy: 1.0000 - val_loss: 5.0273 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 6.7049e-05 - accuracy: 1.0000 - val_loss: 5.0491 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 5.4157e-05 - accuracy: 1.0000 - val_loss: 5.0660 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.6400e-05 - accuracy: 1.0000 - val_loss: 5.0717 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.8471e-05 - accuracy: 1.0000 - val_loss: 5.0755 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.3331e-05 - accuracy: 1.0000 - val_loss: 5.0745 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.9741e-05 - accuracy: 1.0000 - val_loss: 5.0735 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.7061e-05 - accuracy: 1.0000 - val_loss: 5.0726 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.5366e-05 - accuracy: 1.0000 - val_loss: 5.0711 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3988e-05 - accuracy: 1.0000 - val_loss: 5.0698 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.2876e-05 - accuracy: 1.0000 - val_loss: 5.0682 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.1751e-05 - accuracy: 1.0000 - val_loss: 5.0676 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0788e-05 - accuracy: 1.0000 - val_loss: 5.0669 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 1.0064e-05 - accuracy: 1.0000 - val_loss: 5.0661 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 9.4893e-06 - accuracy: 1.0000 - val_loss: 5.0651 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 8.9356e-06 - accuracy: 1.0000 - val_loss: 5.0641 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 8.3668e-06 - accuracy: 1.0000 - val_loss: 5.0637 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 7.9142e-06 - accuracy: 1.0000 - val_loss: 5.0631 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 7.6003e-06 - accuracy: 1.0000 - val_loss: 5.0626 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 7.2156e-06 - accuracy: 1.0000 - val_loss: 5.0623 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 6.7765e-06 - accuracy: 1.0000 - val_loss: 5.0619 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 6.4446e-06 - accuracy: 1.0000 - val_loss: 5.0608 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 6.2077e-06 - accuracy: 1.0000 - val_loss: 5.0600 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.9466e-06 - accuracy: 1.0000 - val_loss: 5.0586 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 5.6932e-06 - accuracy: 1.0000 - val_loss: 5.0576 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 5.5061e-06 - accuracy: 1.0000 - val_loss: 5.0564 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 5.2601e-06 - accuracy: 1.0000 - val_loss: 5.0551 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 5.0806e-06 - accuracy: 1.0000 - val_loss: 5.0544 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.9055e-06 - accuracy: 1.0000 - val_loss: 5.0534 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.7199e-06 - accuracy: 1.0000 - val_loss: 5.0526 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.5615e-06 - accuracy: 1.0000 - val_loss: 5.0521 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.3985e-06 - accuracy: 1.0000 - val_loss: 5.0511 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 4.2778e-06 - accuracy: 1.0000 - val_loss: 5.0500 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.1375e-06 - accuracy: 1.0000 - val_loss: 5.0495 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 4.0092e-06 - accuracy: 1.0000 - val_loss: 5.0486 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.8704e-06 - accuracy: 1.0000 - val_loss: 5.0478 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.7618e-06 - accuracy: 1.0000 - val_loss: 5.0471 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.6728e-06 - accuracy: 1.0000 - val_loss: 5.0461 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.5671e-06 - accuracy: 1.0000 - val_loss: 5.0455 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.4555e-06 - accuracy: 1.0000 - val_loss: 5.0452 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.3634e-06 - accuracy: 1.0000 - val_loss: 5.0442 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 3.2593e-06 - accuracy: 1.0000 - val_loss: 5.0438 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.1854e-06 - accuracy: 1.0000 - val_loss: 5.0431 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.1069e-06 - accuracy: 1.0000 - val_loss: 5.0423 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.0300e-06 - accuracy: 1.0000 - val_loss: 5.0420 - val_accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.9470e-06 - accuracy: 1.0000 - val_loss: 5.0413 - val_accuracy: 0.6500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.8911e-06 - accuracy: 1.0000 - val_loss: 5.0404 - val_accuracy: 0.6500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.7991e-06 - accuracy: 1.0000 - val_loss: 5.0399 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.7553e-06 - accuracy: 1.0000 - val_loss: 5.0393 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.6754e-06 - accuracy: 1.0000 - val_loss: 5.0388 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 2.6180e-06 - accuracy: 1.0000 - val_loss: 5.0382 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 2.5667e-06 - accuracy: 1.0000 - val_loss: 5.0375 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.5124e-06 - accuracy: 1.0000 - val_loss: 5.0370 - val_accuracy: 0.6500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 2.4566e-06 - accuracy: 1.0000 - val_loss: 5.0363 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 2.4098e-06 - accuracy: 1.0000 - val_loss: 5.0356 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 2.3434e-06 - accuracy: 1.0000 - val_loss: 5.0351 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 2.2861e-06 - accuracy: 1.0000 - val_loss: 5.0347 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.2468e-06 - accuracy: 1.0000 - val_loss: 5.0342 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.1985e-06 - accuracy: 1.0000 - val_loss: 5.0337 - val_accuracy: 0.6500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.1412e-06 - accuracy: 1.0000 - val_loss: 5.0332 - val_accuracy: 0.6500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.0990e-06 - accuracy: 1.0000 - val_loss: 5.0328 - val_accuracy: 0.6500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.0582e-06 - accuracy: 1.0000 - val_loss: 5.0321 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.0130e-06 - accuracy: 1.0000 - val_loss: 5.0318 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.9586e-06 - accuracy: 1.0000 - val_loss: 5.0317 - val_accuracy: 0.6500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.9194e-06 - accuracy: 1.0000 - val_loss: 5.0313 - val_accuracy: 0.6500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.8787e-06 - accuracy: 1.0000 - val_loss: 5.0308 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.8349e-06 - accuracy: 1.0000 - val_loss: 5.0305 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.8032e-06 - accuracy: 1.0000 - val_loss: 5.0301 - val_accuracy: 0.6500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.7685e-06 - accuracy: 1.0000 - val_loss: 5.0295 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.7308e-06 - accuracy: 1.0000 - val_loss: 5.0288 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.6900e-06 - accuracy: 1.0000 - val_loss: 5.0283 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.6583e-06 - accuracy: 1.0000 - val_loss: 5.0276 - val_accuracy: 0.6500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.6297e-06 - accuracy: 1.0000 - val_loss: 5.0271 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.5965e-06 - accuracy: 1.0000 - val_loss: 5.0265 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.5708e-06 - accuracy: 1.0000 - val_loss: 5.0259 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.5437e-06 - accuracy: 1.0000 - val_loss: 5.0256 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.5105e-06 - accuracy: 1.0000 - val_loss: 5.0253 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4878e-06 - accuracy: 1.0000 - val_loss: 5.0249 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4622e-06 - accuracy: 1.0000 - val_loss: 5.0247 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4350e-06 - accuracy: 1.0000 - val_loss: 5.0247 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4139e-06 - accuracy: 1.0000 - val_loss: 5.0246 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3837e-06 - accuracy: 1.0000 - val_loss: 5.0245 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3656e-06 - accuracy: 1.0000 - val_loss: 5.0244 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3505e-06 - accuracy: 1.0000 - val_loss: 5.0241 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.3234e-06 - accuracy: 1.0000 - val_loss: 5.0239 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.3037e-06 - accuracy: 1.0000 - val_loss: 5.0235 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.2811e-06 - accuracy: 1.0000 - val_loss: 5.0232 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 1.2675e-06 - accuracy: 1.0000 - val_loss: 5.0227 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.2404e-06 - accuracy: 1.0000 - val_loss: 5.0225 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.2238e-06 - accuracy: 1.0000 - val_loss: 5.0222 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.2072e-06 - accuracy: 1.0000 - val_loss: 5.0221 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.1921e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_three_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXV8zs749Jkc",
        "outputId": "08da257b-7a99-48f9-e217-f0bc4e1f435b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 148ms/step - loss: 5.0217 - accuracy: 0.6500\n",
            "Model 3 Hidden Layer Adam Optimizer Validation Accuracy: 0.6499999761581421\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.8095 - accuracy: 0.5600\n",
            "Best Model Test Accuracy: 0.5600000023841858\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wx0NbEZnPeA",
        "outputId": "a70daa3b-fda9-48af-a3e1-91b13e96810b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n",
            "3       SGD             4                 0.70           0.64\n",
            "4      ADAM             1                 0.70           0.60\n",
            "5      ADAM             2                 0.75           0.64\n",
            "6      ADAM             3                 0.65           0.56\n"
          ]
        }
      ],
      "source": [
        "update_results('ADAM', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlMTpgBG9cO4"
      },
      "source": [
        "#### Train and evaluate the model with 4 hidden Layer with Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCJ24UiW9eZe",
        "outputId": "c5fcb86f-e0cc-4f4e-f825-a113f2d109ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 45ms/step - loss: 1.0040 - accuracy: 0.7975 - val_loss: 3.2403 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.7661 - accuracy: 0.8608 - val_loss: 1.7280 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.3849 - accuracy: 0.8987 - val_loss: 2.1847 - val_accuracy: 0.8000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.5197 - accuracy: 0.9241 - val_loss: 2.6424 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0419 - accuracy: 0.9747 - val_loss: 3.2072 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.1235 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0150 - accuracy: 0.9873 - val_loss: 3.5879 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0130 - accuracy: 0.9873 - val_loss: 4.4584 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0278 - accuracy: 0.9747 - val_loss: 3.9961 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.5203e-04 - accuracy: 1.0000 - val_loss: 4.2054 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.5344e-04 - accuracy: 1.0000 - val_loss: 4.2558 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 8.5763e-05 - accuracy: 1.0000 - val_loss: 4.2819 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 7.0016e-05 - accuracy: 1.0000 - val_loss: 4.2864 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.0649e-05 - accuracy: 1.0000 - val_loss: 4.2885 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.1069e-05 - accuracy: 1.0000 - val_loss: 4.2905 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 3.8488e-05 - accuracy: 1.0000 - val_loss: 4.2923 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.5475e-05 - accuracy: 1.0000 - val_loss: 4.2942 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.3188e-05 - accuracy: 1.0000 - val_loss: 4.2963 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 3.1199e-05 - accuracy: 1.0000 - val_loss: 4.2983 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.9965e-05 - accuracy: 1.0000 - val_loss: 4.3004 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.8700e-05 - accuracy: 1.0000 - val_loss: 4.3026 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.7455e-05 - accuracy: 1.0000 - val_loss: 4.3046 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.6139e-05 - accuracy: 1.0000 - val_loss: 4.3074 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.5182e-05 - accuracy: 1.0000 - val_loss: 4.3100 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.4303e-05 - accuracy: 1.0000 - val_loss: 4.3128 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.3265e-05 - accuracy: 1.0000 - val_loss: 4.3152 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.2449e-05 - accuracy: 1.0000 - val_loss: 4.3177 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.1649e-05 - accuracy: 1.0000 - val_loss: 4.3200 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.0878e-05 - accuracy: 1.0000 - val_loss: 4.3222 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.0251e-05 - accuracy: 1.0000 - val_loss: 4.3241 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.9549e-05 - accuracy: 1.0000 - val_loss: 4.3266 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.8765e-05 - accuracy: 1.0000 - val_loss: 4.3289 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.8154e-05 - accuracy: 1.0000 - val_loss: 4.3309 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.7727e-05 - accuracy: 1.0000 - val_loss: 4.3330 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7281e-05 - accuracy: 1.0000 - val_loss: 4.3353 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.6612e-05 - accuracy: 1.0000 - val_loss: 4.3373 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.6190e-05 - accuracy: 1.0000 - val_loss: 4.3395 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5721e-05 - accuracy: 1.0000 - val_loss: 4.3418 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.5354e-05 - accuracy: 1.0000 - val_loss: 4.3447 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.4900e-05 - accuracy: 1.0000 - val_loss: 4.3474 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4560e-05 - accuracy: 1.0000 - val_loss: 4.3504 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.4130e-05 - accuracy: 1.0000 - val_loss: 4.3527 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3728e-05 - accuracy: 1.0000 - val_loss: 4.3554 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3459e-05 - accuracy: 1.0000 - val_loss: 4.3583 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.3091e-05 - accuracy: 1.0000 - val_loss: 4.3611 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2744e-05 - accuracy: 1.0000 - val_loss: 4.3628 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.2444e-05 - accuracy: 1.0000 - val_loss: 4.3654 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2205e-05 - accuracy: 1.0000 - val_loss: 4.3711 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.1775e-05 - accuracy: 1.0000 - val_loss: 4.3766 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1445e-05 - accuracy: 1.0000 - val_loss: 4.3817 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.1166e-05 - accuracy: 1.0000 - val_loss: 4.3868 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.0861e-05 - accuracy: 1.0000 - val_loss: 4.3924 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.0629e-05 - accuracy: 1.0000 - val_loss: 4.3976 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0315e-05 - accuracy: 1.0000 - val_loss: 4.4026 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0101e-05 - accuracy: 1.0000 - val_loss: 4.4087 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9.8636e-06 - accuracy: 1.0000 - val_loss: 4.4148 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9.4004e-06 - accuracy: 1.0000 - val_loss: 4.4186 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8.7803e-06 - accuracy: 1.0000 - val_loss: 4.4191 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.4468e-06 - accuracy: 1.0000 - val_loss: 4.4215 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 8.1465e-06 - accuracy: 1.0000 - val_loss: 4.4234 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7.9745e-06 - accuracy: 1.0000 - val_loss: 4.4240 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7.7497e-06 - accuracy: 1.0000 - val_loss: 4.4249 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.5400e-06 - accuracy: 1.0000 - val_loss: 4.4257 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7.4072e-06 - accuracy: 1.0000 - val_loss: 4.4275 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.2050e-06 - accuracy: 1.0000 - val_loss: 4.4301 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7.0662e-06 - accuracy: 1.0000 - val_loss: 4.4326 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6.8686e-06 - accuracy: 1.0000 - val_loss: 4.4352 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 6.6256e-06 - accuracy: 1.0000 - val_loss: 4.4372 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6.5517e-06 - accuracy: 1.0000 - val_loss: 4.4388 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 6.2409e-06 - accuracy: 1.0000 - val_loss: 4.4412 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 5.9482e-06 - accuracy: 1.0000 - val_loss: 4.4431 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 5.6826e-06 - accuracy: 1.0000 - val_loss: 4.4464 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 5.4593e-06 - accuracy: 1.0000 - val_loss: 4.4503 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 5.2420e-06 - accuracy: 1.0000 - val_loss: 4.4546 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 4.9116e-06 - accuracy: 1.0000 - val_loss: 4.4576 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.7531e-06 - accuracy: 1.0000 - val_loss: 4.4615 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 4.5690e-06 - accuracy: 1.0000 - val_loss: 4.4674 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 4.4197e-06 - accuracy: 1.0000 - val_loss: 4.4738 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 4.2869e-06 - accuracy: 1.0000 - val_loss: 4.4807 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.1586e-06 - accuracy: 1.0000 - val_loss: 4.4879 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.0681e-06 - accuracy: 1.0000 - val_loss: 4.4914 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 3.9413e-06 - accuracy: 1.0000 - val_loss: 4.4927 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.8478e-06 - accuracy: 1.0000 - val_loss: 4.4957 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.7452e-06 - accuracy: 1.0000 - val_loss: 4.4988 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.6592e-06 - accuracy: 1.0000 - val_loss: 4.5044 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 3.5445e-06 - accuracy: 1.0000 - val_loss: 4.5134 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 3.3996e-06 - accuracy: 1.0000 - val_loss: 4.5194 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 3.2472e-06 - accuracy: 1.0000 - val_loss: 4.5274 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.1461e-06 - accuracy: 1.0000 - val_loss: 4.5369 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.0858e-06 - accuracy: 1.0000 - val_loss: 4.5436 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.9530e-06 - accuracy: 1.0000 - val_loss: 4.5456 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.8941e-06 - accuracy: 1.0000 - val_loss: 4.5493 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 2.8353e-06 - accuracy: 1.0000 - val_loss: 4.5546 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.7689e-06 - accuracy: 1.0000 - val_loss: 4.5606 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.6935e-06 - accuracy: 1.0000 - val_loss: 4.5664 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.6346e-06 - accuracy: 1.0000 - val_loss: 4.5718 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.5743e-06 - accuracy: 1.0000 - val_loss: 4.5772 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.5260e-06 - accuracy: 1.0000 - val_loss: 4.5819 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.4596e-06 - accuracy: 1.0000 - val_loss: 4.5874 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.4203e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_four_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE7-ChDs9l45",
        "outputId": "4b5c0722-c558-4158-a6b6-812b75cb986a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 159ms/step - loss: 4.5917 - accuracy: 0.7500\n",
            "Model 4 Hidden Layer Adam Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.2001 - accuracy: 0.4800\n",
            "Best Model Test Accuracy: 0.47999998927116394\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 4 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EobxfDdNnXVf",
        "outputId": "8c1b5103-dd64-4849-a597-a40933eff1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n",
            "3       SGD             4                 0.70           0.64\n",
            "4      ADAM             1                 0.70           0.60\n",
            "5      ADAM             2                 0.75           0.64\n",
            "6      ADAM             3                 0.65           0.56\n",
            "7      ADAM             4                 0.75           0.48\n"
          ]
        }
      ],
      "source": [
        "update_results('ADAM', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEQaPOOJ9ytE"
      },
      "source": [
        "### 2.B AdaGrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67AwxiCe91ED"
      },
      "source": [
        "#### Train and evaluate the model with 1 hidden Layer with AdaGrad Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-LqJEkx94HA",
        "outputId": "c3be8198-3153-4adc-f81c-eb9bb5be4b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 2s 204ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6353 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 171ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6353 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 170ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6353 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6353 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 162ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 2s 186ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 2s 193ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6352 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 160ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 2s 204ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6351 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 164ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 164ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 163ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 2s 238ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6350 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 2s 214ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6349 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 2s 205ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 4s 512ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 6s 819ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 6s 645ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 174ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 174ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 172ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 19.6348 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 178ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 175ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 174ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 176ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6347 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 2s 188ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 177ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 174ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 171ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 177ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 174ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 177ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 2s 239ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 2s 230ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6346 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 179ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 174ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 188ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 2s 226ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6345 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 179ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 2s 189ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 2s 236ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 19.6344 - val_accuracy: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_one_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms68QG1M9_dU",
        "outputId": "e6a09137-4067-47be-ca66-e0ef02252dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 174ms/step - loss: 19.6344 - accuracy: 0.7000\n",
            "Model 1 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 19.2263 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 1 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkUF9IEPneAF",
        "outputId": "658cf09a-5163-4603-cce6-bd75fb87d313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n",
            "3       SGD             4                 0.70           0.64\n",
            "4      ADAM             1                 0.70           0.60\n",
            "5      ADAM             2                 0.75           0.64\n",
            "6      ADAM             3                 0.65           0.56\n",
            "7      ADAM             4                 0.75           0.48\n",
            "8   AdaGrad             1                 0.70           0.60\n"
          ]
        }
      ],
      "source": [
        "update_results('AdaGrad', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3MJ-cUrEjq2"
      },
      "source": [
        "#### Train and evaluate the model with 2 hidden Layer with AdaGrad Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1QICsdXElpO",
        "outputId": "b75e6777-3c46-4d2b-cac5-7f9bc514605a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 60ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_two_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HFpAJAtEo71",
        "outputId": "af768011-343f-4d1d-9c6b-6932861ed3a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 157ms/step - loss: 11.3903 - accuracy: 0.7500\n",
            "Model 2 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.7588 - accuracy: 0.6400\n",
            "Best Model Test Accuracy: 0.6399999856948853\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoxOlPqwnmwM",
        "outputId": "b211d839-52f2-430e-dde9-03d28f3728e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.75           0.64\n",
            "1       SGD             2                 0.75           0.64\n",
            "2       SGD             3                 0.70           0.68\n",
            "3       SGD             4                 0.70           0.64\n",
            "4      ADAM             1                 0.70           0.60\n",
            "5      ADAM             2                 0.75           0.64\n",
            "6      ADAM             3                 0.65           0.56\n",
            "7      ADAM             4                 0.75           0.48\n",
            "8   AdaGrad             1                 0.70           0.60\n",
            "9   AdaGrad             2                 0.75           0.64\n"
          ]
        }
      ],
      "source": [
        "update_results('AdaGrad', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5kh4TDNFLZb"
      },
      "source": [
        "#### Train and evaluate the model with 3 hidden Layer with AdaGrad Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOreTnywFPRl",
        "outputId": "8ef418dd-b8ff-4579-8b15-ac35b6c05925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 54ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1770e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 1.1710e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.1710e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 1.1694e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 1.1694e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.1694e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1694e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1694e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1679e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1679e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1679e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1664e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1664e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1664e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1664e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1664e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1649e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1649e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1649e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1649e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1649e-06 - accuracy: 1.0000 - val_loss: 5.0218 - val_accuracy: 0.6500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_three_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVlRnqxvFUPv",
        "outputId": "6ac16419-2ef3-4284-fab6-ccc546c89226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 153ms/step - loss: 5.0218 - accuracy: 0.6500\n",
            "Model 3 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.6499999761581421\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.8103 - accuracy: 0.5600\n",
            "Best Model Test Accuracy: 0.5600000023841858\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmGdQnSCntPJ",
        "outputId": "2721f7d3-33d7-46b0-cff4-cd29d2d47b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n"
          ]
        }
      ],
      "source": [
        "update_results('AdaGrad', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoRcbSIJGIVJ"
      },
      "source": [
        "#### Train and evaluate the model with 4 hidden Layer with AdaGrad Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVjrrQwvGKNn",
        "outputId": "997707c2-4db0-44cc-dc78-03bc73ec9790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 43ms/step - loss: 2.3856e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3856e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3841e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3826e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3826e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3826e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3811e-06 - accuracy: 1.0000 - val_loss: 4.5917 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3811e-06 - accuracy: 1.0000 - val_loss: 4.5918 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3796e-06 - accuracy: 1.0000 - val_loss: 4.5918 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.3781e-06 - accuracy: 1.0000 - val_loss: 4.5918 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.3781e-06 - accuracy: 1.0000 - val_loss: 4.5918 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.3781e-06 - accuracy: 1.0000 - val_loss: 4.5918 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.3766e-06 - accuracy: 1.0000 - val_loss: 4.5918 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.3766e-06 - accuracy: 1.0000 - val_loss: 4.5918 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.3751e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.3736e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.3721e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.3721e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.3721e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.3706e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.3690e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 2.3690e-06 - accuracy: 1.0000 - val_loss: 4.5919 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.3675e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.3675e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3675e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3645e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3645e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3645e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3645e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3645e-06 - accuracy: 1.0000 - val_loss: 4.5920 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.3645e-06 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3630e-06 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3615e-06 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3615e-06 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3615e-06 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3600e-06 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3600e-06 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3585e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3585e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3570e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3570e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3570e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3555e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3540e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3540e-06 - accuracy: 1.0000 - val_loss: 4.5922 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3509e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3509e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3509e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3494e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3464e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3464e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3479e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3464e-06 - accuracy: 1.0000 - val_loss: 4.5923 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3464e-06 - accuracy: 1.0000 - val_loss: 4.5924 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3464e-06 - accuracy: 1.0000 - val_loss: 4.5924 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3434e-06 - accuracy: 1.0000 - val_loss: 4.5924 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3419e-06 - accuracy: 1.0000 - val_loss: 4.5924 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3419e-06 - accuracy: 1.0000 - val_loss: 4.5924 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3404e-06 - accuracy: 1.0000 - val_loss: 4.5924 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3404e-06 - accuracy: 1.0000 - val_loss: 4.5924 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.3404e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3389e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3374e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3374e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3374e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3358e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3358e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3343e-06 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3343e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.3313e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3313e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3313e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3283e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3268e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3253e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.3238e-06 - accuracy: 1.0000 - val_loss: 4.5926 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3238e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3238e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3238e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3208e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3208e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3208e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3192e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.3208e-06 - accuracy: 1.0000 - val_loss: 4.5927 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3208e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3192e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3177e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3177e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3177e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3162e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3162e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3147e-06 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.3132e-06 - accuracy: 1.0000 - val_loss: 4.5929 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3132e-06 - accuracy: 1.0000 - val_loss: 4.5929 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.3132e-06 - accuracy: 1.0000 - val_loss: 4.5929 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.3132e-06 - accuracy: 1.0000 - val_loss: 4.5929 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.3117e-06 - accuracy: 1.0000 - val_loss: 4.5929 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.3102e-06 - accuracy: 1.0000 - val_loss: 4.5929 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.3102e-06 - accuracy: 1.0000 - val_loss: 4.5929 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.3087e-06 - accuracy: 1.0000 - val_loss: 4.5930 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_four_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZAGCiBqGPYi",
        "outputId": "e033ad85-cc26-4b28-a7d5-aefbc4edd4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 226ms/step - loss: 4.5930 - accuracy: 0.7500\n",
            "Model 4 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.2078 - accuracy: 0.4800\n",
            "Best Model Test Accuracy: 0.47999998927116394\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 4 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCkaPv9vn096",
        "outputId": "e0701d8e-fc34-4c48-cdba-60949f5a42ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n"
          ]
        }
      ],
      "source": [
        "update_results('AdaGrad', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaxEXMazGclz"
      },
      "source": [
        "### 2.C RMSProp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbPhC4dQGexU"
      },
      "source": [
        "#### Train and evaluate the model with 1 hidden Layer with RMSProp Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCoyReb8GhHa",
        "outputId": "21931822-2d03-4e85-c211-64abaaf03dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 3s 219ms/step - loss: 7.9976e-08 - accuracy: 1.0000 - val_loss: 19.6253 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 189ms/step - loss: 6.7904e-08 - accuracy: 1.0000 - val_loss: 19.6178 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 5.7341e-08 - accuracy: 1.0000 - val_loss: 19.6116 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 5.1305e-08 - accuracy: 1.0000 - val_loss: 19.6062 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 2s 192ms/step - loss: 4.6778e-08 - accuracy: 1.0000 - val_loss: 19.6013 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 4.2251e-08 - accuracy: 1.0000 - val_loss: 19.5970 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 3.9233e-08 - accuracy: 1.0000 - val_loss: 19.5931 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 3.6215e-08 - accuracy: 1.0000 - val_loss: 19.5892 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 188ms/step - loss: 3.3198e-08 - accuracy: 1.0000 - val_loss: 19.5859 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 187ms/step - loss: 3.1689e-08 - accuracy: 1.0000 - val_loss: 19.5828 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 2s 190ms/step - loss: 3.1689e-08 - accuracy: 1.0000 - val_loss: 19.5799 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 188ms/step - loss: 2.8671e-08 - accuracy: 1.0000 - val_loss: 19.5770 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 187ms/step - loss: 2.7162e-08 - accuracy: 1.0000 - val_loss: 19.5744 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 188ms/step - loss: 2.7162e-08 - accuracy: 1.0000 - val_loss: 19.5719 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 2.4144e-08 - accuracy: 1.0000 - val_loss: 19.5696 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 3s 337ms/step - loss: 2.4144e-08 - accuracy: 1.0000 - val_loss: 19.5674 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 3s 328ms/step - loss: 2.2635e-08 - accuracy: 1.0000 - val_loss: 19.5653 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 3s 353ms/step - loss: 2.2635e-08 - accuracy: 1.0000 - val_loss: 19.5633 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 3s 358ms/step - loss: 2.1126e-08 - accuracy: 1.0000 - val_loss: 19.5614 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 4s 482ms/step - loss: 2.1126e-08 - accuracy: 1.0000 - val_loss: 19.5596 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 1.9617e-08 - accuracy: 1.0000 - val_loss: 19.5577 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 3s 321ms/step - loss: 1.9617e-08 - accuracy: 1.0000 - val_loss: 19.5559 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 1.8108e-08 - accuracy: 1.0000 - val_loss: 19.5543 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 4s 541ms/step - loss: 1.8108e-08 - accuracy: 1.0000 - val_loss: 19.5527 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.8108e-08 - accuracy: 1.0000 - val_loss: 19.5510 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 1.8108e-08 - accuracy: 1.0000 - val_loss: 19.5495 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 1.8108e-08 - accuracy: 1.0000 - val_loss: 19.5480 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5466 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5452 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5439 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 2s 235ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5426 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 2s 252ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5413 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5400 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5388 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5376 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 19.5363 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 19.5352 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 19.5341 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5330 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5320 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 187ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5310 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 187ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5300 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5290 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5280 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5270 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5260 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5251 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 2s 239ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5241 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5231 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 19.5221 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 19.5213 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 19.5205 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 19.5197 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 19.5189 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5181 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5173 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5166 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5158 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5150 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5143 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5136 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5128 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5121 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 3s 336ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5114 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 2s 188ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5107 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5100 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5093 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5086 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5079 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5073 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5066 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5059 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5052 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5045 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5039 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 2s 191ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5032 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5025 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 187ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5019 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 2s 221ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5012 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 19.5006 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 2s 194ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.5001 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 2s 210ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4996 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4991 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4986 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4981 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4976 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4971 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 2s 229ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4966 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4961 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4956 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4952 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 2s 236ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4947 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 2s 190ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4942 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 2s 230ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4937 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 2s 252ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4932 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 188ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4928 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4923 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 2s 191ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4919 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4914 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 19.4910 - val_accuracy: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_one_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4wqk_7HGmZd",
        "outputId": "ae5d8c88-19c8-472d-cb53-83bd192ead58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 143ms/step - loss: 19.4910 - accuracy: 0.7000\n",
            "Model 1 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 19.0706 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 1 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kImMzSmtn8yc",
        "outputId": "427a0c1f-5aa5-477d-9320-a1adabce50d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n"
          ]
        }
      ],
      "source": [
        "update_results('RMSprop', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEBF89FnHdNO"
      },
      "source": [
        "#### Train and evaluate the model with 2 hidden Layer with RMSProp Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vigEQ8CHe7v",
        "outputId": "d0df775e-c33c-464e-ee61-beffccb6ff92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3903 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3904 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3905 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3906 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3907 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3908 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3909 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3910 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3910 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3910 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3910 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3910 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3910 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3910 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3911 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3911 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3911 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3911 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3911 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3911 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3911 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3912 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3912 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3912 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3912 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3912 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3912 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3913 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 11.3914 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_two_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkhmAHRpHiDY",
        "outputId": "bf2ef2a4-4fd8-4d17-98f6-2d602d7817ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 147ms/step - loss: 11.3914 - accuracy: 0.7500\n",
            "Model 2 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.7389 - accuracy: 0.6400\n",
            "Best Model Test Accuracy: 0.6399999856948853\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cMYcBbyoIlv",
        "outputId": "30afe1ab-d9d5-41c0-f5ae-32061a6dc45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n",
            "13   RMSprop             2                 0.75           0.64\n"
          ]
        }
      ],
      "source": [
        "update_results('RMSprop', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JTe98PXHsgU"
      },
      "source": [
        "#### Train and evaluate the model with 3 hidden Layer with RMSProp Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoZ8zb9BHuiZ",
        "outputId": "34fa07cb-f2ad-4db2-e748-8222fba0382f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 57ms/step - loss: 1.1679e-06 - accuracy: 1.0000 - val_loss: 5.0219 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.0638e-06 - accuracy: 1.0000 - val_loss: 5.0216 - val_accuracy: 0.6500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 9.6272e-07 - accuracy: 1.0000 - val_loss: 5.0219 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 8.8124e-07 - accuracy: 1.0000 - val_loss: 5.0219 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 8.1032e-07 - accuracy: 1.0000 - val_loss: 5.0215 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 7.5750e-07 - accuracy: 1.0000 - val_loss: 5.0217 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 7.1525e-07 - accuracy: 1.0000 - val_loss: 5.0208 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 6.6847e-07 - accuracy: 1.0000 - val_loss: 5.0203 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 6.3528e-07 - accuracy: 1.0000 - val_loss: 5.0199 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 6.0208e-07 - accuracy: 1.0000 - val_loss: 5.0200 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.7643e-07 - accuracy: 1.0000 - val_loss: 5.0197 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.4927e-07 - accuracy: 1.0000 - val_loss: 5.0200 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.2663e-07 - accuracy: 1.0000 - val_loss: 5.0195 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 5.0551e-07 - accuracy: 1.0000 - val_loss: 5.0194 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.8740e-07 - accuracy: 1.0000 - val_loss: 5.0192 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.6778e-07 - accuracy: 1.0000 - val_loss: 5.0193 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4967e-07 - accuracy: 1.0000 - val_loss: 5.0190 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 4.3609e-07 - accuracy: 1.0000 - val_loss: 5.0191 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 4.2251e-07 - accuracy: 1.0000 - val_loss: 5.0190 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 4.0893e-07 - accuracy: 1.0000 - val_loss: 5.0189 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 3.9837e-07 - accuracy: 1.0000 - val_loss: 5.0188 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 3.8932e-07 - accuracy: 1.0000 - val_loss: 5.0185 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 3.7423e-07 - accuracy: 1.0000 - val_loss: 5.0185 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 3.6517e-07 - accuracy: 1.0000 - val_loss: 5.0184 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.5461e-07 - accuracy: 1.0000 - val_loss: 5.0183 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.4706e-07 - accuracy: 1.0000 - val_loss: 5.0181 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 3.3801e-07 - accuracy: 1.0000 - val_loss: 5.0181 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.3348e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.2292e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.1688e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.0934e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.0330e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.9727e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.9123e-07 - accuracy: 1.0000 - val_loss: 5.0181 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.8369e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.7916e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.7463e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.6860e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.6256e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.5803e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.5502e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 2.5351e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.4596e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.4144e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.3691e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 2.3389e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.2936e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.2786e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.2333e-07 - accuracy: 1.0000 - val_loss: 5.0178 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.1880e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.1578e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.1277e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.0975e-07 - accuracy: 1.0000 - val_loss: 5.0179 - val_accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.0824e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.0522e-07 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.6500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.0220e-07 - accuracy: 1.0000 - val_loss: 5.0181 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.9918e-07 - accuracy: 1.0000 - val_loss: 5.0182 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.9768e-07 - accuracy: 1.0000 - val_loss: 5.0182 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.9466e-07 - accuracy: 1.0000 - val_loss: 5.0181 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.9466e-07 - accuracy: 1.0000 - val_loss: 5.0182 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.8862e-07 - accuracy: 1.0000 - val_loss: 5.0183 - val_accuracy: 0.6500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.8711e-07 - accuracy: 1.0000 - val_loss: 5.0183 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.8259e-07 - accuracy: 1.0000 - val_loss: 5.0184 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 1.8108e-07 - accuracy: 1.0000 - val_loss: 5.0184 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.7806e-07 - accuracy: 1.0000 - val_loss: 5.0184 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 1.7806e-07 - accuracy: 1.0000 - val_loss: 5.0184 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 1.7655e-07 - accuracy: 1.0000 - val_loss: 5.0185 - val_accuracy: 0.6500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.7353e-07 - accuracy: 1.0000 - val_loss: 5.0185 - val_accuracy: 0.6500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.7202e-07 - accuracy: 1.0000 - val_loss: 5.0186 - val_accuracy: 0.6500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.7202e-07 - accuracy: 1.0000 - val_loss: 5.0186 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6901e-07 - accuracy: 1.0000 - val_loss: 5.0186 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6599e-07 - accuracy: 1.0000 - val_loss: 5.0186 - val_accuracy: 0.6500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6448e-07 - accuracy: 1.0000 - val_loss: 5.0187 - val_accuracy: 0.6500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6297e-07 - accuracy: 1.0000 - val_loss: 5.0188 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.6146e-07 - accuracy: 1.0000 - val_loss: 5.0188 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5844e-07 - accuracy: 1.0000 - val_loss: 5.0188 - val_accuracy: 0.6500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5844e-07 - accuracy: 1.0000 - val_loss: 5.0188 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5693e-07 - accuracy: 1.0000 - val_loss: 5.0187 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.5542e-07 - accuracy: 1.0000 - val_loss: 5.0188 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5542e-07 - accuracy: 1.0000 - val_loss: 5.0188 - val_accuracy: 0.6500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5392e-07 - accuracy: 1.0000 - val_loss: 5.0189 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.5090e-07 - accuracy: 1.0000 - val_loss: 5.0190 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.5090e-07 - accuracy: 1.0000 - val_loss: 5.0192 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.4788e-07 - accuracy: 1.0000 - val_loss: 5.0192 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.4486e-07 - accuracy: 1.0000 - val_loss: 5.0192 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.4184e-07 - accuracy: 1.0000 - val_loss: 5.0193 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.4184e-07 - accuracy: 1.0000 - val_loss: 5.0193 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.4033e-07 - accuracy: 1.0000 - val_loss: 5.0193 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.4033e-07 - accuracy: 1.0000 - val_loss: 5.0193 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.3883e-07 - accuracy: 1.0000 - val_loss: 5.0193 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 5.0194 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 5.0194 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 5.0194 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3430e-07 - accuracy: 1.0000 - val_loss: 5.0196 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.3430e-07 - accuracy: 1.0000 - val_loss: 5.0197 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3279e-07 - accuracy: 1.0000 - val_loss: 5.0197 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.3279e-07 - accuracy: 1.0000 - val_loss: 5.0197 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2977e-07 - accuracy: 1.0000 - val_loss: 5.0197 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2977e-07 - accuracy: 1.0000 - val_loss: 5.0198 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.2977e-07 - accuracy: 1.0000 - val_loss: 5.0198 - val_accuracy: 0.6500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_three_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDmK-HTEHu9f",
        "outputId": "46d20bd2-4002-4207-81e7-ced6f80dded8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 210ms/step - loss: 5.0198 - accuracy: 0.6500\n",
            "Model 3 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.6499999761581421\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 7.0093 - accuracy: 0.5600\n",
            "Best Model Test Accuracy: 0.5600000023841858\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaegkS_FoNgk",
        "outputId": "c08a9f68-d7a2-4acd-d87c-bf43f0ce894e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n",
            "13   RMSprop             2                 0.75           0.64\n",
            "14   RMSprop             3                 0.65           0.56\n"
          ]
        }
      ],
      "source": [
        "update_results('RMSprop', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-n1jVk_H9Oe"
      },
      "source": [
        "#### Train and evaluate the model with 4 hidden Layer with RMSProp Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj00XOGcH_z9",
        "outputId": "655f2c33-e4d8-432c-df6a-fccade46d2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.1985e-06 - accuracy: 1.0000 - val_loss: 4.6053 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.7308e-06 - accuracy: 1.0000 - val_loss: 4.6147 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4924e-06 - accuracy: 1.0000 - val_loss: 4.6229 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.3445e-06 - accuracy: 1.0000 - val_loss: 4.6299 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.2343e-06 - accuracy: 1.0000 - val_loss: 4.6363 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.1559e-06 - accuracy: 1.0000 - val_loss: 4.6423 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.0804e-06 - accuracy: 1.0000 - val_loss: 4.6477 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1.0291e-06 - accuracy: 1.0000 - val_loss: 4.6528 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9.7781e-07 - accuracy: 1.0000 - val_loss: 4.6577 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.3556e-07 - accuracy: 1.0000 - val_loss: 4.6623 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.0840e-07 - accuracy: 1.0000 - val_loss: 4.6667 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.6766e-07 - accuracy: 1.0000 - val_loss: 4.6710 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8.3295e-07 - accuracy: 1.0000 - val_loss: 4.6751 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.9976e-07 - accuracy: 1.0000 - val_loss: 4.6790 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.7259e-07 - accuracy: 1.0000 - val_loss: 4.6829 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4845e-07 - accuracy: 1.0000 - val_loss: 4.6867 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.2129e-07 - accuracy: 1.0000 - val_loss: 4.6903 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.0318e-07 - accuracy: 1.0000 - val_loss: 4.6937 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 6.8206e-07 - accuracy: 1.0000 - val_loss: 4.6972 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 6.6546e-07 - accuracy: 1.0000 - val_loss: 4.7005 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 6.4131e-07 - accuracy: 1.0000 - val_loss: 4.7036 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6.2622e-07 - accuracy: 1.0000 - val_loss: 4.7068 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 6.0661e-07 - accuracy: 1.0000 - val_loss: 4.7098 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5.9152e-07 - accuracy: 1.0000 - val_loss: 4.7129 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5.8096e-07 - accuracy: 1.0000 - val_loss: 4.7158 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5.6587e-07 - accuracy: 1.0000 - val_loss: 4.7186 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 5.4927e-07 - accuracy: 1.0000 - val_loss: 4.7214 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5.4021e-07 - accuracy: 1.0000 - val_loss: 4.7241 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5.2663e-07 - accuracy: 1.0000 - val_loss: 4.7268 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 5.1305e-07 - accuracy: 1.0000 - val_loss: 4.7294 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 5.0249e-07 - accuracy: 1.0000 - val_loss: 4.7321 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 4.9343e-07 - accuracy: 1.0000 - val_loss: 4.7346 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.8136e-07 - accuracy: 1.0000 - val_loss: 4.7371 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.7382e-07 - accuracy: 1.0000 - val_loss: 4.7396 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 4.6175e-07 - accuracy: 1.0000 - val_loss: 4.7420 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 4.5269e-07 - accuracy: 1.0000 - val_loss: 4.7444 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.4515e-07 - accuracy: 1.0000 - val_loss: 4.7467 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 4.3609e-07 - accuracy: 1.0000 - val_loss: 4.7490 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 4.3006e-07 - accuracy: 1.0000 - val_loss: 4.7512 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.2251e-07 - accuracy: 1.0000 - val_loss: 4.7535 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 4.1044e-07 - accuracy: 1.0000 - val_loss: 4.7556 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.0591e-07 - accuracy: 1.0000 - val_loss: 4.7578 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.9837e-07 - accuracy: 1.0000 - val_loss: 4.7599 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 3.8932e-07 - accuracy: 1.0000 - val_loss: 4.7620 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.8630e-07 - accuracy: 1.0000 - val_loss: 4.7640 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.7875e-07 - accuracy: 1.0000 - val_loss: 4.7660 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.7423e-07 - accuracy: 1.0000 - val_loss: 4.7680 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.6668e-07 - accuracy: 1.0000 - val_loss: 4.7699 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.6065e-07 - accuracy: 1.0000 - val_loss: 4.7719 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.5310e-07 - accuracy: 1.0000 - val_loss: 4.7738 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3.4857e-07 - accuracy: 1.0000 - val_loss: 4.7756 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.4556e-07 - accuracy: 1.0000 - val_loss: 4.7775 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.4254e-07 - accuracy: 1.0000 - val_loss: 4.7793 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.3801e-07 - accuracy: 1.0000 - val_loss: 4.7811 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.3348e-07 - accuracy: 1.0000 - val_loss: 4.7829 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3.2443e-07 - accuracy: 1.0000 - val_loss: 4.7847 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.2292e-07 - accuracy: 1.0000 - val_loss: 4.7864 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.1689e-07 - accuracy: 1.0000 - val_loss: 4.7882 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.1387e-07 - accuracy: 1.0000 - val_loss: 4.7899 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3.0632e-07 - accuracy: 1.0000 - val_loss: 4.7915 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 3.0481e-07 - accuracy: 1.0000 - val_loss: 4.7932 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.0029e-07 - accuracy: 1.0000 - val_loss: 4.7948 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.9878e-07 - accuracy: 1.0000 - val_loss: 4.7965 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.9274e-07 - accuracy: 1.0000 - val_loss: 4.7980 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.8972e-07 - accuracy: 1.0000 - val_loss: 4.7996 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.8218e-07 - accuracy: 1.0000 - val_loss: 4.8011 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.8218e-07 - accuracy: 1.0000 - val_loss: 4.8027 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.7765e-07 - accuracy: 1.0000 - val_loss: 4.8042 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.7765e-07 - accuracy: 1.0000 - val_loss: 4.8057 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.7312e-07 - accuracy: 1.0000 - val_loss: 4.8072 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.7162e-07 - accuracy: 1.0000 - val_loss: 4.8087 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.6709e-07 - accuracy: 1.0000 - val_loss: 4.8101 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.6407e-07 - accuracy: 1.0000 - val_loss: 4.8116 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.6105e-07 - accuracy: 1.0000 - val_loss: 4.8130 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.5502e-07 - accuracy: 1.0000 - val_loss: 4.8144 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.5351e-07 - accuracy: 1.0000 - val_loss: 4.8159 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.4898e-07 - accuracy: 1.0000 - val_loss: 4.8172 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.4747e-07 - accuracy: 1.0000 - val_loss: 4.8186 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.4445e-07 - accuracy: 1.0000 - val_loss: 4.8199 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 2.4295e-07 - accuracy: 1.0000 - val_loss: 4.8213 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.4144e-07 - accuracy: 1.0000 - val_loss: 4.8226 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 4.8239 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.3540e-07 - accuracy: 1.0000 - val_loss: 4.8252 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 2.3540e-07 - accuracy: 1.0000 - val_loss: 4.8265 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.3238e-07 - accuracy: 1.0000 - val_loss: 4.8278 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.3238e-07 - accuracy: 1.0000 - val_loss: 4.8292 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3087e-07 - accuracy: 1.0000 - val_loss: 4.8304 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.2635e-07 - accuracy: 1.0000 - val_loss: 4.8317 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2.2333e-07 - accuracy: 1.0000 - val_loss: 4.8329 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.2182e-07 - accuracy: 1.0000 - val_loss: 4.8341 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.2031e-07 - accuracy: 1.0000 - val_loss: 4.8353 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.1729e-07 - accuracy: 1.0000 - val_loss: 4.8365 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.1578e-07 - accuracy: 1.0000 - val_loss: 4.8377 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.1277e-07 - accuracy: 1.0000 - val_loss: 4.8389 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.0975e-07 - accuracy: 1.0000 - val_loss: 4.8401 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.0824e-07 - accuracy: 1.0000 - val_loss: 4.8413 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.0824e-07 - accuracy: 1.0000 - val_loss: 4.8424 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.0522e-07 - accuracy: 1.0000 - val_loss: 4.8436 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.0522e-07 - accuracy: 1.0000 - val_loss: 4.8447 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.0371e-07 - accuracy: 1.0000 - val_loss: 4.8459 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_four_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV7OR3ryICEV",
        "outputId": "219a6ea4-8c37-478c-f200-f69972f3667f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 150ms/step - loss: 4.8459 - accuracy: 0.7500\n",
            "Model 4 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7399 - accuracy: 0.4800\n",
            "Best Model Test Accuracy: 0.47999998927116394\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 4 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBZP0voIoSYw",
        "outputId": "05aa2dbd-c610-4987-ccbc-a6f910cd078e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n",
            "13   RMSprop             2                 0.75           0.64\n",
            "14   RMSprop             3                 0.65           0.56\n",
            "15   RMSprop             4                 0.75           0.48\n"
          ]
        }
      ],
      "source": [
        "update_results('RMSprop', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmeHnc1YsBgz"
      },
      "source": [
        "### 2.D Hasil Perbandingan Optimizer SGD, ADAM, AdaGrad, RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "mTse-0aFojOj",
        "outputId": "7ef2beed-cea9-4f4f-fb4d-31b73cf62d9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Membuat palet warna yang berbeda untuk setiap optimizer\n",
        "colors = {'SGD': 'blue', 'Adam': 'green', 'AdaGrad': 'orange', 'RMSprop': 'red'}\n",
        "\n",
        "# Membuat subplots\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "\n",
        "# Grafik akurasi validasi\n",
        "for optimizer, group in results_df.groupby('Optimizer'):\n",
        "    axs[0].bar(group['Optimizer'] + ' ' + group['Hidden Layers'].astype(str), group['Validation Accuracy'], color=colors.get(optimizer, 'black'), label=optimizer)\n",
        "axs[0].set_title('Validation Accuracy')\n",
        "axs[0].set_xlabel('Model', fontsize=10)  # Penyesuaian ukuran font\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=45, ha='right')  # Rotasi label sumbu x\n",
        "axs[0].legend()\n",
        "\n",
        "# Grafik akurasi pengujian\n",
        "for optimizer, group in results_df.groupby('Optimizer'):\n",
        "    axs[1].bar(group['Optimizer'] + ' ' + group['Hidden Layers'].astype(str), group['Test Accuracy'], color=colors.get(optimizer, 'black'), label=optimizer)\n",
        "axs[1].set_title('Test Accuracy')\n",
        "axs[1].set_xlabel('Model', fontsize=10)  # Penyesuaian ukuran font\n",
        "axs[1].set_ylabel('Accuracy')\n",
        "axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=45, ha='right')  # Rotasi label sumbu x\n",
        "axs[1].legend()\n",
        "\n",
        "# Menampilkan grafik\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "2flTOQ8MscmV",
        "outputId": "128974e7-6fdc-437c-efe0-64b26356b159"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
              "0        SGD             1                 0.75           0.64\n",
              "1        SGD             2                 0.75           0.64\n",
              "2        SGD             3                 0.70           0.68\n",
              "3        SGD             4                 0.70           0.64\n",
              "4       ADAM             1                 0.70           0.60\n",
              "5       ADAM             2                 0.75           0.64\n",
              "6       ADAM             3                 0.65           0.56\n",
              "7       ADAM             4                 0.75           0.48\n",
              "8    AdaGrad             1                 0.70           0.60\n",
              "9    AdaGrad             2                 0.75           0.64\n",
              "10   AdaGrad             3                 0.65           0.56\n",
              "11   AdaGrad             4                 0.75           0.48\n",
              "12   RMSprop             1                 0.70           0.60\n",
              "13   RMSprop             2                 0.75           0.64\n",
              "14   RMSprop             3                 0.65           0.56\n",
              "15   RMSprop             4                 0.75           0.48"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab993f79-71bb-441b-b4d6-aae3cd6b88fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Hidden Layers</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SGD</td>\n",
              "      <td>3</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SGD</td>\n",
              "      <td>4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab993f79-71bb-441b-b4d6-aae3cd6b88fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab993f79-71bb-441b-b4d6-aae3cd6b88fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab993f79-71bb-441b-b4d6-aae3cd6b88fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c409e05-79bf-4c41-945e-154b9788ddc7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c409e05-79bf-4c41-945e-154b9788ddc7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c409e05-79bf-4c41-945e-154b9788ddc7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ADAM\",\n          \"RMSprop\",\n          \"SGD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hidden Layers\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03966002290332003,\n        \"min\": 0.6499999761581421,\n        \"max\": 0.75,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.75,\n          0.699999988079071,\n          0.6499999761581421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06449806239300764,\n        \"min\": 0.47999998927116394,\n        \"max\": 0.6800000071525574,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6800000071525574,\n          0.47999998927116394,\n          0.6000000238418579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Menampilkan DataFrame\n",
        "display(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgdEHufkrdwC",
        "outputId": "ed45c86a-4454-4fd5-ff3a-2624b0bec5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dengan akurasi pengujian tertinggi:\n",
            "Optimizer               SGD\n",
            "Hidden Layers             3\n",
            "Validation Accuracy     0.7\n",
            "Test Accuracy          0.68\n",
            "Name: 2, dtype: object\n",
            "\n",
            "Model dengan akurasi pengujian terendah:\n",
            "Optimizer              ADAM\n",
            "Hidden Layers             4\n",
            "Validation Accuracy    0.75\n",
            "Test Accuracy          0.48\n",
            "Name: 7, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Temukan indeks baris dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_idx = results_df['Test Accuracy'].idxmax()\n",
        "worst_model_idx = results_df['Test Accuracy'].idxmin()\n",
        "\n",
        "# Dapatkan informasi tentang model dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_info = results_df.loc[best_model_idx]\n",
        "worst_model_info = results_df.loc[worst_model_idx]\n",
        "\n",
        "print(\"Model dengan akurasi pengujian tertinggi:\")\n",
        "print(best_model_info)\n",
        "print(\"\\nModel dengan akurasi pengujian terendah:\")\n",
        "print(worst_model_info)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux_JFcoEv1Jt"
      },
      "source": [
        "## 3. Menambahkan Dropout 50%"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.A Menambahkan Dropout di salah satu layer"
      ],
      "metadata": {
        "id": "VuV6NxULeJR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "yQLoXTcixR9v"
      },
      "outputs": [],
      "source": [
        "# Function to build the DNN model with one hidden layer\n",
        "def build_model_one_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(1000, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer with 1000 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')          # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to build the DNN model with two hidden layer\n",
        "def build_model_two_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(500, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # 1st hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(500, activation='relu'),                                   # 2nd hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to build the DNN model with three hidden layer\n",
        "def build_model_three_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(250, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Second hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Third hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to build the DNN model with four hidden layer\n",
        "def build_model_four_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Second hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Third hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Fourth hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Ovt6qsAIys18"
      },
      "outputs": [],
      "source": [
        "# Build the DNN model\n",
        "model_one_hidden_layer_with_dropout = build_model_one_hidden_with_dropout()\n",
        "model_two_hidden_layer_with_dropout = build_model_two_hidden_with_dropout()\n",
        "model_three_hidden_layer_with_dropout = build_model_three_hidden_with_dropout()\n",
        "model_four_hidden_layer_with_dropout = build_model_four_hidden_with_dropout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFZMsLntyDkt"
      },
      "source": [
        "#### SGD - Train and evaluate the model with 1 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upboAKNMyWRR",
        "outputId": "8759cb04-c218-4d42-ee2e-d37b35b966d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 1.7538 - accuracy: 0.5316 - val_loss: 0.8045 - val_accuracy: 0.8000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.1512 - accuracy: 0.9367 - val_loss: 1.6400 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.1117 - accuracy: 0.9620 - val_loss: 1.1964 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 0.0274 - accuracy: 0.9873 - val_loss: 0.9561 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.8000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.8000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1882 - val_accuracy: 0.8000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1740 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0105 - accuracy: 0.9873 - val_loss: 1.1640 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1451 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2658 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2504 - val_accuracy: 0.8000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2350 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.6889e-04 - accuracy: 1.0000 - val_loss: 1.2357 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2359 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2355 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 109ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2607 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2735 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2727 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 4.6574e-04 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2651 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 4.4451e-04 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 6.3130e-04 - accuracy: 1.0000 - val_loss: 1.2595 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 5.0456e-04 - accuracy: 1.0000 - val_loss: 1.2553 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 6.6526e-04 - accuracy: 1.0000 - val_loss: 1.2526 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 5.8324e-04 - accuracy: 1.0000 - val_loss: 1.2517 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 4.8557e-04 - accuracy: 1.0000 - val_loss: 1.2532 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2386 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 7.1268e-04 - accuracy: 1.0000 - val_loss: 1.2414 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2487 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 7.5777e-04 - accuracy: 1.0000 - val_loss: 1.2432 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 2.7706e-04 - accuracy: 1.0000 - val_loss: 1.2453 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 7.5846e-04 - accuracy: 1.0000 - val_loss: 1.2502 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 4.1907e-04 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 0.0359 - accuracy: 0.9873 - val_loss: 1.1521 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 5.9187e-04 - accuracy: 1.0000 - val_loss: 1.1473 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 6.9847e-04 - accuracy: 1.0000 - val_loss: 1.1568 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 8.9213e-04 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 2.4415e-04 - accuracy: 1.0000 - val_loss: 1.1581 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.7525e-04 - accuracy: 1.0000 - val_loss: 1.1586 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1560 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 135ms/step - loss: 7.0899e-04 - accuracy: 1.0000 - val_loss: 1.1556 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 136ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 6.3160e-04 - accuracy: 1.0000 - val_loss: 1.1526 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 5.5724e-04 - accuracy: 1.0000 - val_loss: 1.1506 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 2.7260e-04 - accuracy: 1.0000 - val_loss: 1.1512 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 3.1290e-04 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 3.9699e-04 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 3.1501e-04 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 5.4150e-04 - accuracy: 1.0000 - val_loss: 1.1601 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 3.9495e-04 - accuracy: 1.0000 - val_loss: 1.1605 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 106ms/step - loss: 4.5035e-04 - accuracy: 1.0000 - val_loss: 1.1611 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 7.2744e-04 - accuracy: 1.0000 - val_loss: 1.1619 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 4.8425e-04 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 4.0340e-04 - accuracy: 1.0000 - val_loss: 1.1609 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.1585e-04 - accuracy: 1.0000 - val_loss: 1.1618 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 5.1983e-04 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 4.4920e-04 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 4.8884e-04 - accuracy: 1.0000 - val_loss: 1.1672 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 2.9369e-04 - accuracy: 1.0000 - val_loss: 1.1685 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 6.0835e-04 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 2.2758e-04 - accuracy: 1.0000 - val_loss: 1.1752 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 2.2150e-04 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 2.5391e-04 - accuracy: 1.0000 - val_loss: 1.1738 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 2.8678e-04 - accuracy: 1.0000 - val_loss: 1.1735 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 3.2819e-04 - accuracy: 1.0000 - val_loss: 1.1756 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 5.8558e-04 - accuracy: 1.0000 - val_loss: 1.1739 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 4.9079e-04 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 2.2518e-04 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 3.3354e-04 - accuracy: 1.0000 - val_loss: 1.1845 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.0152e-04 - accuracy: 1.0000 - val_loss: 1.1772 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 7.3789e-04 - accuracy: 1.0000 - val_loss: 1.1779 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 5.8728e-04 - accuracy: 1.0000 - val_loss: 1.1733 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 3.0727e-04 - accuracy: 1.0000 - val_loss: 1.1747 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 4.9781e-04 - accuracy: 1.0000 - val_loss: 1.1800 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 5.1610e-04 - accuracy: 1.0000 - val_loss: 1.1792 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 5.5726e-04 - accuracy: 1.0000 - val_loss: 1.1780 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 6.1182e-04 - accuracy: 1.0000 - val_loss: 1.1858 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 2.7168e-04 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 4.7250e-04 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 6.0051e-04 - accuracy: 1.0000 - val_loss: 1.1894 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.0878e-04 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.4265e-04 - accuracy: 1.0000 - val_loss: 1.1905 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.9531e-04 - accuracy: 1.0000 - val_loss: 1.1915 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 5.5735e-04 - accuracy: 1.0000 - val_loss: 1.1944 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 3.8377e-04 - accuracy: 1.0000 - val_loss: 1.1936 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 2.2634e-04 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 6.8256e-04 - accuracy: 1.0000 - val_loss: 1.1876 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 2.3576e-04 - accuracy: 1.0000 - val_loss: 1.1886 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 4.7486e-04 - accuracy: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 134ms/step - loss: 3.8855e-04 - accuracy: 1.0000 - val_loss: 1.1892 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 2s 306ms/step - loss: 5.5889e-04 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 2s 245ms/step - loss: 1.2166e-04 - accuracy: 1.0000 - val_loss: 1.1930 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 3.7764e-04 - accuracy: 1.0000 - val_loss: 1.1937 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 3.9685e-04 - accuracy: 1.0000 - val_loss: 1.1931 - val_accuracy: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "# optimizer_sgd = tf.keras.optimizers.SGD(learning_rate=0.01)  # Define the optimizer with learning rate\n",
        "model_one_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JNF5onKzMtW",
        "outputId": "f21847c9-b8cb-4e24-db23-c0295e606b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 155ms/step - loss: 1.1931 - accuracy: 0.7000\n",
            "Model Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4047 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X17iNYBXzR-_",
        "outputId": "b4b17a20-b51f-4b34-932c-bf95a94481e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n",
            "13   RMSprop             2                 0.75           0.64\n",
            "14   RMSprop             3                 0.65           0.56\n",
            "15   RMSprop             4                 0.75           0.48\n",
            "16     SGD+D             1                 0.70           0.60\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD+D', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.B Menambahkan Dropout di semua layer"
      ],
      "metadata": {
        "id": "L5oKbza6eUdM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh84YYGJyJje"
      },
      "source": [
        "#### SGD - Train and evaluate the model with 2 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpJsI-9gycRD",
        "outputId": "ad2045be-65e8-49ef-91fc-d1041caffa57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 1.0325 - accuracy: 0.5949 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.2462 - accuracy: 0.8987 - val_loss: 0.6479 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0892 - accuracy: 0.9620 - val_loss: 0.6011 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0275 - accuracy: 0.9873 - val_loss: 0.7335 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7503 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7699 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7750 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7849 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7928 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8314 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8329 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8290 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8301 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8334 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8366 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8418 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8426 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 8.7725e-04 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8450 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8680 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 6.0802e-04 - accuracy: 1.0000 - val_loss: 0.8705 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 65ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8757 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 9.3807e-04 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8832 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 3.7108e-04 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 8.8062e-04 - accuracy: 1.0000 - val_loss: 0.8809 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.0386e-04 - accuracy: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8809 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 9.6352e-04 - accuracy: 1.0000 - val_loss: 0.8827 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 9.2237e-04 - accuracy: 1.0000 - val_loss: 0.8832 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 9.8190e-04 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 5.5474e-04 - accuracy: 1.0000 - val_loss: 0.8849 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 8.8200e-04 - accuracy: 1.0000 - val_loss: 0.8862 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.7384e-04 - accuracy: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8901 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 6.0115e-04 - accuracy: 1.0000 - val_loss: 0.8900 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 7.6561e-04 - accuracy: 1.0000 - val_loss: 0.8925 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.6049e-04 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8968 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.5174e-04 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 8.4605e-04 - accuracy: 1.0000 - val_loss: 0.8968 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8932 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 5.8343e-04 - accuracy: 1.0000 - val_loss: 0.8950 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 6.0715e-04 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 9.5190e-04 - accuracy: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 6.0071e-04 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 7.9132e-04 - accuracy: 1.0000 - val_loss: 0.9056 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.8934e-04 - accuracy: 1.0000 - val_loss: 0.9057 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_two_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwjT0dniyKty"
      },
      "source": [
        "#### SGD - Train and evaluate the model with 3 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf3FhJMDyYJn",
        "outputId": "5b0a448d-258e-4244-bace-b2050b09862f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 0.8170 - accuracy: 0.5696 - val_loss: 0.4458 - val_accuracy: 0.8000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2749 - accuracy: 0.9367 - val_loss: 0.4466 - val_accuracy: 0.8500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1209 - accuracy: 0.9873 - val_loss: 0.4134 - val_accuracy: 0.8500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1288 - accuracy: 0.9747 - val_loss: 0.4473 - val_accuracy: 0.8000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0557 - accuracy: 0.9873 - val_loss: 0.4516 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5957 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5978 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6099 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.9485e-04 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8.9276e-04 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6297 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 6.3100e-04 - accuracy: 1.0000 - val_loss: 0.6379 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8.1607e-04 - accuracy: 1.0000 - val_loss: 0.6384 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 6.5834e-04 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 6.4532e-04 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_three_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88kGQAjMzyqi",
        "outputId": "cfc97f55-c188-4280-bc05-139560f62e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 153ms/step - loss: 0.9057 - accuracy: 0.7500\n",
            "Model 2 Hidden Layer SGD Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.9844 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# 5. Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# 6. Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyI3oLO0z6vY",
        "outputId": "ce62b180-d65b-4bac-e6c7-9942e806c227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n",
            "13   RMSprop             2                 0.75           0.64\n",
            "14   RMSprop             3                 0.65           0.56\n",
            "15   RMSprop             4                 0.75           0.48\n",
            "16     SGD+D             1                 0.70           0.60\n",
            "17     SGD+D             2                 0.75           0.60\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD+D', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPXAb-SB0Keo",
        "outputId": "b465b422-acf6-4009-fe54-e569d94f33a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 152ms/step - loss: 0.6483 - accuracy: 0.7500\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0951 - accuracy: 0.5600\n",
            "Best Model Test Accuracy: 0.5600000023841858\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq5Ybvoz0T88",
        "outputId": "59b43bec-822e-4a39-e5fe-0c008c0f2f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n",
            "13   RMSprop             2                 0.75           0.64\n",
            "14   RMSprop             3                 0.65           0.56\n",
            "15   RMSprop             4                 0.75           0.48\n",
            "16     SGD+D             1                 0.70           0.60\n",
            "17     SGD+D             2                 0.75           0.60\n",
            "18     SGD+D             3                 0.75           0.56\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD+D', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5XOintSyL4J"
      },
      "source": [
        "#### SGD - Train and evaluate the model with 4 hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz4Zfyf-yjHn",
        "outputId": "b7b3a359-f3ab-43dc-8582-ca988cffb6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 38ms/step - loss: 0.7113 - accuracy: 0.5570 - val_loss: 0.5864 - val_accuracy: 0.8500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.4131 - accuracy: 0.8608 - val_loss: 0.5437 - val_accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3369 - accuracy: 0.9114 - val_loss: 0.5072 - val_accuracy: 0.8000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2014 - accuracy: 0.9620 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1466 - accuracy: 0.9873 - val_loss: 0.4975 - val_accuracy: 0.8000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0957 - accuracy: 0.9873 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.7436 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7539 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.7727 - val_accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7897 - val_accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.8000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.8000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8159 - val_accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8273 - val_accuracy: 0.8000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.8000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8371 - val_accuracy: 0.8000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8388 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8496 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.8000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8642 - val_accuracy: 0.8000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.8686 - val_accuracy: 0.8000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8580 - val_accuracy: 0.8000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8631 - val_accuracy: 0.8000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.8000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.8000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8803 - val_accuracy: 0.8000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8852 - val_accuracy: 0.8000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.8000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.8878 - val_accuracy: 0.8000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.8000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9060 - val_accuracy: 0.8000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9115 - val_accuracy: 0.8000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9198 - val_accuracy: 0.8000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9256 - val_accuracy: 0.8000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9230 - val_accuracy: 0.8000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.8000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9274 - val_accuracy: 0.8000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.8000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9443 - val_accuracy: 0.8000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9508 - val_accuracy: 0.8000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.8000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.8000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.8000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9734 - val_accuracy: 0.8000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.8000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9868 - val_accuracy: 0.8000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.8000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.8000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0068 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0259 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0289 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0449 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0470 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0600 - val_accuracy: 0.8000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 7.7562e-04 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.8000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.8000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.8000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0628 - val_accuracy: 0.8000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0659 - val_accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0690 - val_accuracy: 0.8000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0719 - val_accuracy: 0.8000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.8000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0800 - val_accuracy: 0.8000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0837 - val_accuracy: 0.8000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.8000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0889 - val_accuracy: 0.8000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0982 - val_accuracy: 0.8000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.8000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.8000\n"
          ]
        }
      ],
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_four_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6lcrKw00jbQ",
        "outputId": "57aa355b-6296-40fa-d5d7-3946c711c131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 154ms/step - loss: 1.1056 - accuracy: 0.8000\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.800000011920929\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4271 - accuracy: 0.5200\n",
            "Best Model Test Accuracy: 0.5199999809265137\n"
          ]
        }
      ],
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kqYtKpt0tYT",
        "outputId": "6f9801b0-e525-4053-e8a4-1c9aa9d51453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.75           0.64\n",
            "1        SGD             2                 0.75           0.64\n",
            "2        SGD             3                 0.70           0.68\n",
            "3        SGD             4                 0.70           0.64\n",
            "4       ADAM             1                 0.70           0.60\n",
            "5       ADAM             2                 0.75           0.64\n",
            "6       ADAM             3                 0.65           0.56\n",
            "7       ADAM             4                 0.75           0.48\n",
            "8    AdaGrad             1                 0.70           0.60\n",
            "9    AdaGrad             2                 0.75           0.64\n",
            "10   AdaGrad             3                 0.65           0.56\n",
            "11   AdaGrad             4                 0.75           0.48\n",
            "12   RMSprop             1                 0.70           0.60\n",
            "13   RMSprop             2                 0.75           0.64\n",
            "14   RMSprop             3                 0.65           0.56\n",
            "15   RMSprop             4                 0.75           0.48\n",
            "16     SGD+D             1                 0.70           0.60\n",
            "17     SGD+D             2                 0.75           0.60\n",
            "18     SGD+D             3                 0.75           0.56\n",
            "19     SGD+D             4                 0.80           0.52\n"
          ]
        }
      ],
      "source": [
        "update_results('SGD+D', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCE5O4uR028V"
      },
      "source": [
        "### 3.C Hasil Penambahan Dropout 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "MImc1AD-1Lp_",
        "outputId": "892ff6f6-b6f4-4792-ce33-58fbe56fed85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
              "0        SGD             1                 0.75           0.64\n",
              "1        SGD             2                 0.75           0.64\n",
              "2        SGD             3                 0.70           0.68\n",
              "3        SGD             4                 0.70           0.64\n",
              "4       ADAM             1                 0.70           0.60\n",
              "5       ADAM             2                 0.75           0.64\n",
              "6       ADAM             3                 0.65           0.56\n",
              "7       ADAM             4                 0.75           0.48\n",
              "8    AdaGrad             1                 0.70           0.60\n",
              "9    AdaGrad             2                 0.75           0.64\n",
              "10   AdaGrad             3                 0.65           0.56\n",
              "11   AdaGrad             4                 0.75           0.48\n",
              "12   RMSprop             1                 0.70           0.60\n",
              "13   RMSprop             2                 0.75           0.64\n",
              "14   RMSprop             3                 0.65           0.56\n",
              "15   RMSprop             4                 0.75           0.48\n",
              "16     SGD+D             1                 0.70           0.60\n",
              "17     SGD+D             2                 0.75           0.60\n",
              "18     SGD+D             3                 0.75           0.56\n",
              "19     SGD+D             4                 0.80           0.52"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-505cd583-0951-4f82-bba7-0c6c9616dca9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Hidden Layers</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SGD</td>\n",
              "      <td>3</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SGD</td>\n",
              "      <td>4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-505cd583-0951-4f82-bba7-0c6c9616dca9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-505cd583-0951-4f82-bba7-0c6c9616dca9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-505cd583-0951-4f82-bba7-0c6c9616dca9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8e9d3a3-9667-41b1-9595-4a6212acef40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8e9d3a3-9667-41b1-9595-4a6212acef40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8e9d3a3-9667-41b1-9595-4a6212acef40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ADAM\",\n          \"SGD+D\",\n          \"AdaGrad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hidden Layers\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041278907215750886,\n        \"min\": 0.6499999761581421,\n        \"max\": 0.800000011920929,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.699999988079071,\n          0.800000011920929,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05985948645662242,\n        \"min\": 0.47999998927116394,\n        \"max\": 0.6800000071525574,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6399999856948853,\n          0.6800000071525574,\n          0.5199999809265137\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Menampilkan DataFrame\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zguDGXib1REK",
        "outputId": "520f9b5a-4660-4d25-8dd9-be555bf41864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dengan akurasi pengujian tertinggi:\n",
            "Optimizer               SGD\n",
            "Hidden Layers             3\n",
            "Validation Accuracy     0.7\n",
            "Test Accuracy          0.68\n",
            "Name: 2, dtype: object\n",
            "\n",
            "Model dengan akurasi pengujian terendah:\n",
            "Optimizer              ADAM\n",
            "Hidden Layers             4\n",
            "Validation Accuracy    0.75\n",
            "Test Accuracy          0.48\n",
            "Name: 7, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Temukan indeks baris dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_idx = results_df['Test Accuracy'].idxmax()\n",
        "worst_model_idx = results_df['Test Accuracy'].idxmin()\n",
        "\n",
        "# Dapatkan informasi tentang model dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_info = results_df.loc[best_model_idx]\n",
        "worst_model_info = results_df.loc[worst_model_idx]\n",
        "\n",
        "print(\"Model dengan akurasi pengujian tertinggi:\")\n",
        "print(best_model_info)\n",
        "print(\"\\nModel dengan akurasi pengujian terendah:\")\n",
        "print(worst_model_info)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}